---
title: "CCR Statistics"
author: "M.Mave"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    code_folding: hide
    code_download: yes
editor_options:
  markdown:
    wrap: 72
---
#   {.tabset}

# R setup
Set working directory and load necessary libraries to run code.
```{r setup, include=FALSE, }
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

setwd("C:/Users/MMave/OneDrive - haleyaldrich.com/Vectren Corporation - Documents/0129420.Culley/Deliverables/East Ash Pond/0_Statistical Evaluation/May 2025")

#Load libraries for following code
# tinytex::install_tinytex(force = TRUE)
#reading, writing, and manipulating data
library(tinytex)
library(tibble)
library(vctrs)
library(RODBC)
library(lemon)
library(dplyr)
library(tidyr)
library(stringr)
library(writexl)
library(readxl)
library(flextable)
library(webshot)
library(kableExtra)
library(mblm)
library(reshape2)
library(magick)

#Plotting
library(scales)  
library(ggplot2)
library(grid) 
library(stats) #Shapiro Wilk Test, Kruskall Wallis Test
library(tolerance) #UTL
library(trend) #Sens Slope
library(boot) #Bootstrap testing
library(outliers) #Rosner Dixon testing
library(EnvStats) #Descriptive Statistics functions, tolerance interval k calc, etc.
library(Kendall) #Mann Kendall
library(DescTools) #Shapiro Francia test for UTLs - Sample Size > 50
#library(NADA)
library(car) #Levene's test for equal variance

#prevent sci notation for visuals
options(scipen = 999) 

#create directories as needed to write out files
dir.create("output files")
dir.create("output files/Combined Plots_original data")
dir.create("output files/6a_Background")
dir.create("output files/report tables")
dir.create("output files/Appx")
dir.create("output files/6b_LCL check")


```

#Define event ID and user name 
```{r Fields to Update Each Event}

Event <- "May 2025"
Statistics.Date <- ""
User <- ""
Data.Screen.End.Date <- "2025-03-30"
UTL.Update.Date <- "2025-07-30" #Typically updated annually following the 1st semi-annual event
UPL.Update.Date <- "2025-07-30" #Generally update every other year, 1st semi-annual event
old.UPL.date <- "2023-07-30" #For comparison testing prior to update

background.wells <- c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9")
downgradient <- c("CCR-AP-2", "CCR-AP-3", "CCR-AP-4R","CCR-AP-5","CCR-AP-6","CCR-AP-8")
upls <- "Arsenic, Total" #only run intrawell analysis for arsenic at this unit :)

input.filename <- "input files/2413210__HAI Analytical Results v1_1_8 Prototype_20250801120045.csv"
```

   
##LOAD DATA AND FILTER FOR ANALYTE/WELL PAIRS OF INTEREST####
```{r Load data}
index <- read.csv("input files/Evaluated Analyte_Well Pairs and SLs.csv")
wells <- unique(index$Location)
chems <- unique(index$Chemical)
mcl <- index %>% 
  select(Chemical, MCL.RSL) %>% 
  distinct()

data_stats <- read.csv(input.filename) %>%
  mutate(detect_flag = ifelse(detect_flag == "Y", "Yes", "No"),
         StatResult_RL = as.numeric(report_result_value),
         StatResult_RL = ifelse(report_result_unit == "ug/L", StatResult_RL/1000, StatResult_RL),
         StatResult_0.5RL = ifelse(detect_flag == "No", 0.5*StatResult_RL, StatResult_RL),
         report_result_unit = ifelse(report_result_unit == "ug/L", "mg/L", 
                                     ifelse(report_result_unit == "pH units", "SU", 
                                            report_result_unit)),
         sample_date = as.Date(sample_date, format ="%m/%d/%Y"),
         Location = sys_loc_code,
         Location = gsub("CCR-AP-4", "CCR-AP-4R", Location),
         Chemical = chemical_name,
         Stats.Chem = ifelse(Chemical %in% c("Radium-226 & 228","Radium-226 & 228, Total"), "Yes",
                             ifelse(Chemical == "Fluoride", "Yes",
                             ifelse(fraction == "T", "Yes", "No"))),
         Chemical = ifelse(Chemical %in% c("Radium-226 & 228","Radium-226 & 228, Total"), "Radium-226 & 228", Chemical),
         key = paste(Location, Chemical, sep = "_"),
         remove = ifelse(Location == "CCR-AP-1R" & Chemical == "Radium-226 & 228" & sample_date == "2023-11-02", "Y", #replaced with re-sample results
                         ifelse(Location %in% c("CCR-AP-4R", "CCR-AP-2", "CCR-AP-1R") & Chemical == "Radium-226 & 228" & sample_date %in% c("2024-11-14", "2024-11-15"), "Y", #replaced with re-sample results
                                ifelse(Location == "CCR-AP-7" & sample_date == "2024-07-15", "Y",#replaced with re-sample results
                                       ifelse(Location == "CCR-AP-1R" & Chemical == "Radium-226 & 228" & sample_date == "2023-11-02", "Y", #replaced with re-sample results
                                              ifelse(Location == "CCR-AP-8" & sample_date == "2025-05-29", "Y", #Actually from well 8I
                                              "N"))))),
         task_code = ifelse(sample_date > "2024-01-01", "Round X", task_code)) %>% 
  filter(Location %in% wells,
         remove == "N",
         task_code != "",
         grepl("Round", task_code),
         final_qualifiers != "R", #Remove rejected/unuseable results
         reportable_result == "Yes",
         report_result_unit != "mg/kg", #Remove solids data
         matrix_code == "WG", #Remove any WQ or solids data, alt approach
         sample_type_code != "FD",
         Chemical %in% chems) %>%
  left_join(index %>% select(-Location), by = "Chemical") %>% 
  distinct() %>% 
  select(c(key, Chemical, Location, sample_date, matrix_code, sample_type_code, final_qualifiers, 
           StatResult_RL, StatResult_0.5RL, report_result_unit, detect_flag, longitude, latitude, task_code)) %>%  
  distinct()

#Check that you have all data
if(length(unique(data_stats$Chemical)) == 15){"proceed"}else{"check"}

if(length(unique(data_stats$Location)) == 9){"proceed"}else{"check locations"}

if(max(data_stats$sample_date) > Data.Screen.End.Date){"proceed"}else{"check input file and filters above for dates"}

unique(data_stats$final_qualifiers)
```

#Add pooled background dataset for testing
```{r}

pooled_background <- data_stats %>%
  filter(Location %in% c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9")) %>%
  mutate(Location = ifelse(Location %in% c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9"), "Pooled Background",
                "Remove"),
         key = paste(Location, Chemical, sep = "_"))

data_stats <- bind_rows(data_stats, pooled_background)

```


##Initial inspection of sample counts
For future analysis, remove rejected data***
```{r}
#Only look at sets with 8 or more data points per unified guidance (other guidance says > 8 needed for reliable statistics)
sufficient.samples <- data_stats %>%
  group_by(key) %>%
  summarize(count = n()) %>%
  filter(count >= 8)
not.enough.samples <- data_stats %>%
  group_by(key) %>%
  summarize(count = n()) %>%
  filter(count < 8)
{
print("Well.copcs pairs with < 8 data points, insufficient data for stats analysis: ")
print(nrow(not.enough.samples))
}
```

## 0_Test for data independence####
```{r 0_Data Independence}
indep <- data_stats %>% 
  mutate(month = as.Date(sample_date, format = "%m")) %>% 
  separate(month, into = c("Year", "Month", "Day"), sep = "-") %>% 
  group_by(Location, Chemical, key, Year, Month) %>% 
  summarise(n = n()) %>% 
  filter(n > 1)
write.csv(indep, "output files/0_Data independence issues_inspect.csv")

independence_eval <- data_stats %>% 
  mutate(month = as.Date(sample_date, format = "%m")) %>% 
  separate(month, into = c("Year", "Month", "Day"), sep = "-") %>% 
  right_join(indep, by = c("key", "Location", "Chemical", "Year", "Month"))
write.csv(independence_eval, "output files/0_Data independence issues_inspect discrete data.csv", row.names = F)

```

#Diagnostic Methods and Testing
##1_Descriptive Stats
```{r}
stat_sum <- data_stats %>%  
  ungroup() %>% 
  group_by(Location, Chemical) %>% 
  summarise(n = n(),
            max = max(StatResult_RL),
            min = min(StatResult_RL),
            mean = mean(StatResult_RL),
            median = median(StatResult_RL),
            sd = sd(StatResult_RL),
            variance = var(StatResult_RL),
            min_date = min(sample_date),
            max_date = max(sample_date))

stat_sum_nd <- data_stats %>%  
  group_by(Location, Chemical, detect_flag) %>%
  filter(detect_flag == "No") %>% 
  summarise(n_nd = n(),
            max_RL = max(StatResult_RL),
            min_RL = min(StatResult_RL))

stat_sum_final <- left_join(stat_sum, stat_sum_nd, by = c("Location", "Chemical")) %>% 
  select(c(1:3, 13, 14, 15, 4:9, 10,11)) %>% 
  mutate(`Percent of non-detects` = ifelse(n_nd == "NA", 0, n_nd/n*100),
         across(c(n_nd, `Percent of non-detects`), ~if_else(is.na(.), 0, .))) 
write.csv(stat_sum_final, "output files/1_Stats summary.csv", row.names = F)
```

## 2_Shapiro Wilk test for normality
```{r}
#Test all wells and pooled data for normality
{
summary <- NULL
summary_nd <- NULL

keys <- unique(data_stats$key)

for(k in keys){
  
  k_data <- data_stats %>%  
    filter(key == k)
  
  n_all <- as.numeric(nrow(k_data))
  n_nd <- as.numeric(nrow(k_data %>%  filter(detect_flag == "No")))
  l <- unique(k_data$Location)
  a <- unique(k_data$Chemical)
  
  if(n_all*0.5 < n_nd){
    
    results_df_nd <- data.frame(
      key = k,
      Site = "Vectren, AB Brown",
      Location = l,
      Chemical = a,
      WStatistic.SW = "Majority (>50% ND)",
      PValue.SW = "Majority (>50% ND)",
      n = n_all,
      n_nd = n_nd)
    
    summary_nd <- bind_rows(results_df_nd, summary_nd)
      
  } else if (n_all != n_nd){
  
    res <- shapiro.test(k_data$StatResult_0.5RL)
    
    results_df <- data.frame(
      key = k,
      Site = "Vectren, AB Brown",
      Location = l,
      Chemical = a,
      Analysis = "Shapiro-Wilk test for normality (ND = 0.5*RL)",
      WStatistic.SW = res$statistic,
      PValue.SW = res$p.value,
      n = n_all,
      n_nd = n_nd)
    
    summary <- bind_rows(results_df, summary)
  }
}

#Combine summaries and write test output
##If n > 30 consider using a confidence level of 99%
summary <- summary %>% 
  mutate(Distribution.99 = ifelse(PValue.SW > 0.01, "Normal", "Not normal"),
         WStatistic.SW = as.character(WStatistic.SW),
         PValue.SW = as.character(PValue.SW))
summary_nd <- summary_nd %>% 
  mutate(Distribution.99 = "Not Evaluated - Majority (>50% ND)",
         WStatistic.SW = as.character(WStatistic.SW),
         PValue.SW = as.character(PValue.SW))

summary_SW <- bind_rows(summary, summary_nd) %>%  select(-Site)

}

# Test distribution of all for lognormality
{
summaryln <- NULL
summaryln_nd <- NULL

keys <- unique(data_stats$key)

for(k in keys){
  
  k_data <- data_stats %>%  
    filter(key == k) %>% 
    mutate(StatResult_RL = log(StatResult_RL),
           StatResult_0.5RL = log(StatResult_0.5RL))
  
  n_all <- as.numeric(nrow(k_data))
  n_nd <- as.numeric(nrow(k_data %>%  filter(detect_flag == "No")))
  l <- unique(k_data$Location)
  a <- unique(k_data$Chemical)
  
  if(n_all*0.5 < n_nd){
    
    results_df_nd <- data.frame(
      key = k,
      Site = "Vectren, AB Brown",
      Location = l,
      Chemical = a,
      WStatistic.SWln = "Majority (>50% ND)",
      PValue.SWln = "Majority (>50% ND)",
      n = n_all,
      n_nd = n_nd)
    
    summaryln_nd <- bind_rows(results_df_nd, summaryln_nd)
      
  } else if (n_all != n_nd){
  
    res <- shapiro.test(k_data$StatResult_0.5RL)
    
    results_df <- data.frame(
      key = k,
      Site = "Vectren, AB Brown",
      Location = l,
      Chemical = a,
      Analysis = "Shapiro-Wilk test for normality (ND = 0.5*RL)",
      WStatistic.SWln = res$statistic,
      PValue.SWln = res$p.value,
      n = n_all,
      n_nd = n_nd)
    
    summaryln <- bind_rows(results_df, summaryln)
  }
}

#Combine summaries and write test output
##If n > 30 consider using a confidence level of 99%
summaryln <- summaryln %>% 
  mutate(Distribution.99ln = ifelse(PValue.SWln > 0.01, "Lognormal", "Not lognormal"),
         WStatistic.SWln = as.character(WStatistic.SWln),
         PValue.SWln = as.character(PValue.SWln))
summaryln_nd <- summaryln_nd %>% 
  mutate(Distribution.99ln = "Not Evaluated - Majority (>50% ND)",
         WStatistic.SWln = as.character(WStatistic.SWln),
         PValue.SWln = as.character(PValue.SWln))

summary_SWln <- bind_rows(summaryln, summaryln_nd) 

}

# Combine summaries and write test output
summary_SW <- left_join(summary_SW, summary_SWln) %>% 
  mutate(Selected.Distribution = ifelse(Distribution.99 == "Normal", "Normal",
                                        ifelse(Distribution.99ln == "Lognormal", "Lognormal", "Not normal"))) %>% 
  select(-Site)
write.csv(summary_SW, "output files/2_Shapiro-Wilk Normality Test Results.csv", row.names = F)

#Test all for normality and lognormality and interpret at 99% confidence....this is a broad stroke analysis of the data
##When the distribution is important for decision making, either in BTV calcs or LCL calcs, distributions may be re-evaluated through visual review
```

## 3_Outlier Test - Rosner or Dixon (n)
```{r}
#groups with more than 8 samples

sample_counts <- data_stats %>%
  group_by(key) %>%
  summarize(count = n())

#add k column to Outlier Analysis
outlier_data <- left_join(data_stats, sample_counts, by = "key")

Rosner <- filter(outlier_data, count > 25)
Dixon <- filter(outlier_data, count <= 25)

#Run Rosner/Dixon on datasets with outliers identified above
summary_D <- NULL

for(i in unique(Dixon$key)){
  
  #group the dataset
  df_sub <- filter(Dixon, key==i)
  
  n_nd <- nrow(df_sub %>%  filter(detect_flag == "No"))
  n_all <- nrow(df_sub)
  
  if(n_nd == n_all){
    
    result <- cbind("Dixon",i, n_all, n_nd, "All results are non-detects.", "NA", "NA")
  }else if(n_all < 3){
    
    result <- cbind("Dixon",i, n_all, n_nd, "Less than 3 results.", "NA", "NA") 
    
  } else {
    
    #Dixon Test
    dixon_test <- dixon.test(df_sub$StatResult_0.5RL)
    
    #combine all results together into one row
    result <- cbind("Dixon",i, n_all, n_nd, formatC(dixon_test$statistic,digits = 4), dixon_test$alternative, dixon_test$p.value)
    
  }
  
  #combine the above result to previous results to form a summary table
  summary_D <- rbind(summary_D,result)
  colnames(summary_D) <- c("Outlier Test", "key", "n", "n_nd", "Statistic.Out", "Alternative", "P.value.Out")
  
}


summary_R <- NULL

for(i in unique(Rosner$key)){ 
  
  #group the dataset
  df_sub <- filter(Rosner, key==i)
  
  n_nd <- nrow(df_sub %>%  filter(detect_flag == "No"))
  n_all <- nrow(df_sub)
  
  if(n_nd == n_all){
    
    result <- cbind("Rosner",i, n_all, n_nd, "All results are non-detects.", "NA", "NA")
    
  } else {
    
    #Rosner Test
    rosner_test <- rosnerTest(df_sub$StatResult_0.5RL)
    #combine all results together into one row
    result <- cbind("Rosner", i, n_all, n_nd, paste(formatC(rosner_test$statistic, digits = 4), collapse = ",\n"),
                    paste(formatC(rosner_test$crit.value,digits = 4),collapse = ",\n"), paste(rosner_test$n.outliers, collapse = ",\n"))
  }
  
  #combine the above result to previous results to form a summary table
  summary_R <- rbind(summary_R,result)
  colnames(summary_R) <- c("Outlier Test", "key", "n", "n_nd", "Statistic.Out", "Critical.Value.Out", "n of potential outliers (Rosner)")
  
}

summary_RD <- bind_rows(as.data.frame(summary_D), as.data.frame(summary_R)) %>% 
  mutate(n = as.numeric(n), n_nd = as.numeric(n_nd))

#write results to csv
write.csv(summary_RD, "output files/2_Dixon_Rosner Outlier Test Restuls.csv", row.names = F)

Sig.Outlier.Results <- summary_RD %>% 
  mutate(pct_nds = as.numeric(n_nd) / as.numeric(n)) %>% 
  filter(P.value.Out < 0.05,
         Statistic.Out != "All results are non-detects.",
         pct_nds < 0.50,
         Statistic.Out > 0.05) %>% 
  mutate(Statistical.Outlier = "Yes")

outlier.res <- Sig.Outlier.Results %>% 
  mutate(key = key,
         outlier = gsub("highest value ", "", Alternative),
         outlier = gsub("lowest value ", "", outlier),
         outlier = gsub(" is an outlier", "", outlier),
         StatResult_0.5RL = as.numeric(outlier)) %>% 
  select(-c(n, n_nd))
write.csv(outlier.res, "output files/3_Dixon_Rosner Statistically Significant Outliers.csv", row.names = F)

data_copc_out <- left_join(data_stats, outlier.res, 
            by = c("key", "StatResult_0.5RL")) %>% 
  mutate(outlier.detect = ifelse(detect_flag == "No", "No", 
                                 ifelse(is.na(outlier), "No",
                                        "Yes")))

```

## 3_Spatial Variability
```{r}
#Side by Side Box Plots
  ggplot(data = data_stats %>% 
           filter(Location != "Pooled Background") %>% 
           mutate(Group = ifelse(Location %in% c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9"),
                                 "Background", "Downgradient"))) +
      stat_boxplot(aes(x = Group, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Group, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "black",
                   outlier.shape = 1,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = sprintf("Concentration"))+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )+
    facet_wrap(~paste(Chemical, report_result_unit, sep = ", "), scales = "free_y")
ggsave("output files/3_Spatial variability box plots_Up vs Down-gradient.png", width = 17, height = 11)

  ggplot(data = data_stats%>% 
           filter(Location != "Pooled Background")) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "black",
                   outlier.shape = 1,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )+
    facet_wrap(~paste(Chemical, report_result_unit, sep = ", "), scales = "free_y")
  ggsave("output files/3_Spatial variability box plots.png", width = 17, height = 11)
  
    ggplot(data = data_stats %>% 
           filter(Location != "Pooled Background",
                  Location %in% c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9"))) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "black",
                   outlier.shape = 1,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots: Background Wells",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )+
    facet_wrap(~paste(Chemical, report_result_unit, sep = ", "), scales = "free_y")
  ggsave("output files/3_Spatial variability box plots_Background Wells.png", width = 17, height = 11)

    ggplot(data = data_stats %>% 
           filter(Location != "Pooled Background",
                  !Location %in% c("CCR-AP-1R", "CCR-AP-7", "CCR-AP-9"))) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "black",
                   outlier.shape = 1,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )+
    facet_wrap(~paste(Chemical, report_result_unit, sep = ", "), scales = "free_y")
    
  ggsave("output files/3_Spatial variability box plots_Downgradient Wells.png", width = 17, height = 11)
  
  
```

## 4_Temporal Stationarity - Seasonality, Kruskal Wallis test (non-parametric)####
```{r}
#create new data frame fields for processing
data_copc_out["month"] <- format(data_copc_out$sample_date, "%m")

#Set up season groups with look up table
month <- c("01","02","03","04","05", "06", "07", "08", "09", "10", "11", "12")
sgroup <- c(1,1,2,2,2,3,3,3,4,4,4,1)
lookup <- cbind.data.frame(month, sgroup)
Stats <- left_join(data_copc_out, lookup, by='month')

summary_KW <- NULL

key_list <- unique(Stats$key)

#Run seasonality analysis with zero for non-detects
#for loop to automate the analysis for different analytes and monitoring sites
for(i in key_list){
  #group the dataset
  df_sub <- subset(Stats, key == i)
  
  nSeasons <- length(unique(df_sub$sgroup))
  nResults <- nrow(df_sub)
  nND <- nrow(filter(df_sub, detect_flag == "No"))
  
  if(nSeasons == 1) {
    stat <- "Only One Season"
    p <- "Not Evaluated - Only One Season"
  } else if(nResults == nND) {
    stat <- "All ND"
    p <- "Not Evaluated - No detected results"
  } else if (min(df_sub$StatResult_0.5RL)==max(df_sub$StatResult_0.5RL)) {
    stat <- "One unique result"
    p <- "Not Evaluated - Only one unique result"
  } else if(nResults < 8) {
    stat <- "Less than 8 results"
    p <- "Not Evaluated - Less than 8 results"
  } else if(nND > 0.5*nResults) {
    stat <- "Greater than 50% non-detect reuslts"
    p <- "Not Evaluated - Greater than 50% non-detect results"
  } else {
    
    #Kruskal Wallis Test
    kw_test <- kruskal.test(df_sub$StatResult_0.5RL ~ df_sub$sgroup)
    
    stat <- kw_test$statistic
    p <- kw_test$p.value
    
  }
  
  Location <- unique(df_sub$Location)[1]
  Chemical <- unique(df_sub$Chemical)[1]
  
  
  result <- cbind(Location, Chemical, nSeasons, nResults, nND, stat, p)
  summary_KW <- rbind(result, summary_KW)
  
}

colnames(summary_KW) <- c("Location", "Chemical", "nSeasons", "nResults", "n_nd", "Statistic_kw", "P.value_kw")
summary_KW <- as.data.frame(summary_KW) %>% 
  mutate(n_nd = as.numeric(n_nd))

seasonality.review <- as.data.frame(summary_KW) %>% 
  mutate(Seasonality.identified = ifelse(P.value_kw == "Not Evaluated - No detected results", P.value_kw, 
                                         ifelse(P.value_kw == "Not Evaluated - Only one unique result", P.value_kw,
                                                ifelse(P.value_kw == "Not Evaluated - Greater than 50% non-detect results", P.value_kw,
                                                ifelse(as.numeric(P.value_kw) < 0.01 & 
                                                         (as.numeric(n_nd) / as.numeric(nResults)) < 0.5,
                                                "Yes", "No")))),
         Analysis = "Kruskal Wallis test for seasonality, no outliers removed, ND = 0.5*RL",
         key = paste(Location, Chemical, sep = "_"),
         n_nd = as.numeric(n_nd))

seasonal_trend_groups <- seasonality.review %>%  filter(Seasonality.identified == "Yes")
seasonal_trend_groups <- unique(seasonal_trend_groups$key)

#combine results into dataset
data_copc_out_kw <- left_join(Stats, seasonality.review, 
                           by = c("Location", "Chemical", "key")) %>%  
  distinct() %>% 
  mutate(confirm = ifelse(Seasonality.identified == "Yes", "Confirm trend by visual inspection",
                          "NA"))
  
#write results summary to csv
write.csv(data_copc_out_kw, "output files/4a_Kruskal Wallis Seasonality Test.csv", row.names = F, na = "")

if(length(seasonal_trend_groups)>0){
  ggplot(data = data_copc_out_kw %>%
           filter(key %in% seasonal_trend_groups))+
    geom_point(aes(x = sample_date, y = StatResult_0.5RL, color = as.character(sgroup)))+
    geom_line(aes(x = sample_date, y = StatResult_0.5RL))+
    facet_wrap(~key, scales = "free")+
    theme_bw()
ggsave("output files/4_Seasonality review.png", width = 11, height = 8)
}
seasonality.review <-  seasonality.review %>% 
  mutate(Seasonality.corrected = ifelse(Seasonality.identified == "No", "NA - Not Identified", "Yes"))

############ADJUST SEASONALLY TRENDING DATA#####################################
SeasonalMeans <- data_copc_out_kw %>% 
  filter(confirm == "Yes") %>% 
  group_by(Location, Chemical, sgroup) %>%
  summarize(SAve = mean(StatResult_RL))

UniversalMeans <- data_copc_out_kw %>% 
  filter(confirm == "Yes") %>% 
  group_by(Location, Chemical) %>%
  summarize(UAve = mean(StatResult_RL))

Stats_s <- left_join(data_copc_out_kw, SeasonalMeans, by = c("Location", "Chemical","sgroup")) %>% 
  filter(confirm == "Yes")
Stats_su <- left_join(Stats_s, UniversalMeans, by = c("Location", "Chemical"))

SeasonalAdjustment <- Stats_su %>%
  mutate(StatResult_Seas.Adj = ifelse(is.na(SAve), StatResult_0.5RL,StatResult_0.5RL-SAve+UAve),
         StatResult_Seas.Adj = ifelse(StatResult_0.5RL<0, 0,StatResult_Seas.Adj))

data_copc_out_adj <- left_join(data_copc_out_kw, SeasonalAdjustment) %>% 
  mutate(StatResult_Seas.Adj = ifelse(is.na(StatResult_Seas.Adj), StatResult_0.5RL, StatResult_Seas.Adj))
write.csv(data_copc_out_adj, "output files/4b_SeasonallyAdjusted_Data.csv", row.names = F, na ="")


seasonal.adj.list.confirmed <- unique(SeasonalAdjustment$key)
  
```

## 5_Secular Trend Analysis
```{r}

MK_Stats <- data_copc_out_adj
write.csv(MK_Stats, "output files/5a_Trend analysis input data.csv")

Trend_Sites <- unique(MK_Stats$key)

#for loop to automate the analysis for different sites
summary_MK <- NULL
for(site in Trend_Sites){
  #get a subset of data where Site is equal to site
  data_sub <- MK_Stats %>% 
    filter(key==site) %>% 
    arrange(sample_date)
  
  nResults <- nrow(data_sub)
  nValues <- length(unique(data_sub$StatResult_Seas.Adj))
  nDetects <- nrow(filter(data_sub, detect_flag == "Yes"))
  l <- data_sub$Location[1]
  a <- data_sub$Chemical[1]
  appendix <- data_sub$Appendix
  min_date <- as.Date(min(data_sub$sample_date), format = "%Y-%m-%d")
  max_date <- as.Date(max(data_sub$sample_date), format = "%Y-%m-%d")
  years <- (as.numeric(max_date) - as.numeric(min_date))/365
  if(nResults < 8) {
    
    mk_t <- "NA"
    mk_p <- "Less than 8 results"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
    
  
  } else if(nDetects < 1) {
    
    mk_t <- "NA"
    mk_p <- "No detected results"
    mk_Score <- "NA"
    mk_var.S <- "NA"    
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
    
  } else if(nDetects < 2) {
    
    mk_t <- "NA"
    mk_p <- "Only one detected result"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
  
  } else if(nValues < 2) {
    
    mk_t <- "NA"
    mk_p <- "Only one unique result"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
  
  } else if(nDetects/nResults < 0.5) {
    
    mk_t <- "NA"
    mk_p <- "Majority of data (>50%) non-detect"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
  } else {
    minDate <- min(data_sub$sample_date)
    
    data_sub <- mutate(data_sub, DateNum = as.numeric(sample_date - minDate + 1))
    
    #Mann Kendall Test (On seasonally adjusted data where applicable)
    mk_test <- MannKendall(data_sub$StatResult_Seas.Adj)
    mk_t <- format(mk_test$tau[1], digits = 3)
    mk_p <- format(mk_test$sl[1], digits = 3)
    mk_Score <- format(mk_test$S[1], digits = 3)
    mk_var.S <- format(mk_test$varS[1], digits = 3)
    mk_conf.factor <- format((1 - (as.numeric(mk_p)))*100  , digits = 3)
    mk_D <- format(mk_test$D[1], digits = 3)
    r_max <- format(max(data_sub$StatResult_Seas.Adj), digits = 3)
    mk_test <- "Mann-Kendall Test (function = MannKendall, Kendall package, R programming)"
    
    #COV
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)                    
    
    #Sen Slope
    sen <- zyp.sen(StatResult_Seas.Adj ~ DateNum, data_sub)                                                  
    senslope <-  coef(sen)[2]
    sen_test <- "Thiel Sen Test (function = sens.slope, zyp.sen package, R programming)"
    INTERCEPT <- coef(sen)[1]

  }
  
  #combine all results together into one row
  result=cbind(l, a, appendix, nResults, nDetects, nValues, 
               mk_t, mk_p, mk_conf.factor,  mk_Score, mk_var.S, r_max, mk_test, 
               COV, senslope, sen_test, INTERCEPT, years
               ) 
  
  #combine the above result to previous results to form a summary table
  summary_MK=rbind(summary_MK,result) 
}
summary_MK <- as.data.frame(summary_MK)

####summarise trends####
secular_trends <- summary_MK %>% 
  mutate(mk_p_num = as.numeric(mk_p),
         mk_t_num = as.numeric(mk_t),
         mk_conf.factor_num = as.numeric(mk_conf.factor),
         mk_Score_num = as.numeric(mk_Score),
         COV_num = as.numeric(COV),
         Trend = ifelse(mk_t == "NA", paste0("Not Evaluated - ", mk_p),
                        ifelse(mk_p_num > 0.05, "No Trend", 
                               ifelse(mk_p_num < 0.05 & mk_t_num < 0, "Decreasing",
                                      "Increasing"))),
         Trend_Aziz.2003 = ifelse(mk_t == "NA", paste0("Not Evaluated - ", mk_p),
                                  ifelse(is.na(mk_conf.factor_num), "All tied values (p is NaN).",
                                         ifelse(mk_Score_num > 0 & mk_conf.factor_num > 95, "Increasing",
                                                ifelse(mk_Score_num > 0 & mk_conf.factor_num >= 90 & mk_conf.factor_num <= 95, "Probably Increasing",
                                                       ifelse(mk_Score_num > 0 & mk_conf.factor_num < 90, "No Trend",
                                                              ifelse(mk_Score_num <= 0 & mk_conf.factor_num < 90 & COV_num >= 1, "No Trend",
                                                                     ifelse(mk_Score_num <= 0 & mk_conf.factor_num < 90 & COV < 1,"Stable",
                                                                            ifelse(mk_Score_num < 0 & mk_conf.factor_num >= 90 & mk_conf.factor_num <= 95, "Probably Decreasing",
                                                                                   ifelse(mk_Score_num < 0 & mk_conf.factor_num > 95, "Decreasing",
                                                                                          "ERROR. Condition not found"))))))))),
         senslope = ifelse(Trend_Aziz.2003 %in% c("Increasing", "Decreasing"), senslope, "NA"),
         years = as.numeric(years),
         days = as.numeric(years/365),
         slope = as.numeric(senslope),
         rate_per_year = (slope*days)/(days/365)) %>% 
  distinct() %>% 
  mutate(Chemical = a, Location = l, key = paste(Location, Chemical, sep = "_")) %>%  
  select(-c(a, l, mk_p_num, mk_t_num, COV_num, mk_Score_num, mk_conf.factor_num)) %>% 
  select(c(key, Chemical, Location, Trend, Trend_Aziz.2003, nResults, nDetects, nValues, r_max, COV, 
           mk_test, mk_t, mk_p, mk_conf.factor, mk_Score, mk_var.S,
           sen_test, senslope, rate_per_year, INTERCEPT)) %>% 
  mutate(Seasonally.Adjusted.Data = ifelse(key %in% seasonal.adj.list.confirmed, "Yes", "No"))

summary_MK8 <- NULL

for(site in Trend_Sites){
  #get a subset of data where Site is equal to site
  data_sub <- MK_Stats %>% 
    filter(key==site) %>% 
    arrange(sample_date)
  data_sub <- arrange(data_sub, desc(sample_date))[(1:8),] %>% 
    arrange(sample_date) %>% 
    filter(!is.na(StatResult_0.5RL))
  
  nResults <- nrow(data_sub)
  nValues <- length(unique(data_sub$StatResult_Seas.Adj))
  nDetects <- nrow(filter(data_sub, detect_flag == "Yes"))
  l <- data_sub$Location[1]
  a <- data_sub$Chemical[1]
  appendix <- data_sub$Appendix
  min_date <- as.Date(min(data_sub$sample_date), format = "%Y-%m-%d")
  max_date <- as.Date(max(data_sub$sample_date), format = "%Y-%m-%d")
  years <- (as.numeric(max_date) - as.numeric(min_date))/365
  if(nDetects < 1) {
    
    mk_t <- "NA"
    mk_p <- "No detected results"
    mk_Score <- "NA"
    mk_var.S <- "NA"    
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
    
  } else if(nDetects < 2) {
    
    mk_t <- "NA"
    mk_p <- "Only one detected result"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
    } else if(nResults < 8) {
    
    mk_t <- "NA"
    mk_p <- "Less than 8 results"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
    
  } else if(nValues < 2) {
    
    mk_t <- "NA"
    mk_p <- "Only one unique result"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
  } else if(nDetects/nResults < 0.50) {
    
    mk_t <- "NA"
    mk_p <- "Majority of data (>50%) non-detect"
    mk_Score <- "NA"
    mk_var.S <- "NA"
    mk_conf.factor <- "NA"
    r_max=max(data_sub$StatResult_Seas.Adj)
    mk_test <- "Dataset does not meet requirements for Mann Kendall Trend Test."
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)
    senslope <-  "NA"
    INTERCEPT <- "NA"
    sen_test <- "Dataset does not meet requirements for Thiel-Send Trend Test."   
    
  } else {
    
    minDate <- min(data_sub$sample_date)
    
    data_sub <- mutate(data_sub, DateNum = as.numeric(sample_date - minDate + 1))
    
    #Mann Kendall Test (On seasonally adjusted data where applicable)
    mk_test <- MannKendall(data_sub$StatResult_Seas.Adj)
    mk_t <- format(mk_test$tau[1], digits = 3)
    mk_p <- format(mk_test$sl[1], digits = 3)
    mk_Score <- format(mk_test$S[1], digits = 3)
    mk_var.S <- format(mk_test$varS[1], digits = 3)
    mk_conf.factor <- format((1 - (as.numeric(mk_p)))*100  , digits = 3)
    mk_D <- format(mk_test$D[1], digits = 3)
    r_max <- format(max(data_sub$StatResult_Seas.Adj), digits = 3)
    mk_test <- "Mann-Kendall Test (function = MannKendall, Kendall package, R programming)"
    
    #COV
    COV <- format(sd(data_sub$StatResult_Seas.Adj, na.rm=TRUE) / 
                    mean(data_sub$StatResult_Seas.Adj, na.rm=TRUE), digits = 3)                    
    sen <- zyp.sen(StatResult_Seas.Adj ~ DateNum, data_sub)                                                  
    senslope <-  coef(sen)[2]
    sen_test <- "Thiel Sen Test (function = sens.slope, zyp.sen package, R programming)"
    INTERCEPT <- coef(sen)[1]
    
  }
  
  #combine all results together into one row
  result8=cbind(l, a, appendix, nResults, nDetects, nValues, 
               mk_t, mk_p, mk_conf.factor, mk_D, mk_Score, mk_var.S, r_max, mk_test, 
               COV, 
               senslope, INTERCEPT, years) 
  
  #combine the above result to previous results to form a summary table
  summary_MK8=rbind(summary_MK8,result8) 
}

summary_MK8 <- as.data.frame(summary_MK8)

####summarise trends####
secular_trends8 <- summary_MK8 %>% 
  mutate(mk_p_num = as.numeric(mk_p),
         mk_t_num = as.numeric(mk_t),
         mk_conf.factor_num = as.numeric(mk_conf.factor),
         mk_Score_num = as.numeric(mk_Score),
         COV_num = as.numeric(COV),
         Trend = ifelse(mk_t == "NA", paste0("Not Evaluated - ", mk_p),
                        ifelse(mk_p_num > 0.05, "No Trend", 
                               ifelse(mk_p_num < 0.05 & mk_t_num < 0, "Decreasing",
                                      "Increasing"))),
         Trend_Aziz.2003 = ifelse(mk_t == "NA", paste0("Not Evaluated - ", mk_p),
                                  ifelse(is.na(mk_conf.factor_num), "All tied values (p is NaN).",
                                         ifelse(mk_Score_num > 0 & mk_conf.factor_num > 95, "Increasing",
                                                ifelse(mk_Score_num > 0 & mk_conf.factor_num >= 90 & mk_conf.factor_num <= 95, "Probably Increasing",
                                                       ifelse(mk_Score_num > 0 & mk_conf.factor_num < 90, "No Trend",
                                                              ifelse(mk_Score_num <= 0 & mk_conf.factor_num < 90 & COV_num >= 1, "No Trend",
                                                                     ifelse(mk_Score_num <= 0 & mk_conf.factor_num < 90 & COV < 1,"Stable",
                                                                            ifelse(mk_Score_num < 0 & mk_conf.factor_num >= 90 & mk_conf.factor_num <= 95, "Probably Decreasing",
                                                                                   ifelse(mk_Score_num < 0 & mk_conf.factor_num > 95, "Decreasing",
                                                                                          "ERROR. Condition not found"))))))))),
         senslope = ifelse(Trend_Aziz.2003 %in% c("Increasing", "Decreasing"), senslope, "NA"),
         years = as.numeric(years),
         days = as.numeric(years/365),
         slope = as.numeric(senslope),
         rate_per_year = (slope*days)/(days/365)) %>% 
  distinct() %>% 
  mutate(Chemical = a, Location = l, key = paste(Location, Chemical, sep = "_")) %>%  
  select(-c(a, l, mk_p_num, mk_t_num, COV_num, mk_Score_num, mk_conf.factor_num)) %>% 
  select(c(key, Chemical, Location, Trend_Aziz.2003, nResults, nDetects, nValues, r_max, COV,
           mk_test, mk_t, mk_p, mk_conf.factor, mk_Score, mk_var.S,
           senslope, INTERCEPT, rate_per_year)) 
#print(colnames(secular_trends8))
colnames(secular_trends8) <- c("key"        ,          
                               "Chemical"            ,   "Location"        ,      
                               "Trend8_Aziz.2003"   ,     "nResults8"           ,   
                              "nDetects8"      ,         "nValues8"        ,       
                              "r_max8"       ,           "COV8"   ,  
                              "mk_test8"          ,      "mk_t8"                ,  
                              "mk_p8"             ,      "mk_conf.factor8"   ,     
                              "mk_Score8"     ,          "mk_var.S8"              ,
                              "senslope8"  , "intercept8",     "rate_per_year8"
)

#export
#write.csv(secular_trends8,'output files/5_Trend Analysis_Recent8 data_revised.csv')


#combined POR and 8 results
mk_summary_all <- left_join(secular_trends, secular_trends8, by= c("key", "Chemical", "Location")) %>% 
  mutate(senslope8 = ifelse(Trend8_Aziz.2003 %in% c("Increasing", "Decreasing"), senslope8, "NA"),
         rate_per_year8 = ifelse(Trend8_Aziz.2003 %in% c("Increasing", "Decreasing"), rate_per_year8, "NA"),
         intercept8 = ifelse(Trend8_Aziz.2003 %in% c("Increasing", "Decreasing"), intercept8, "NA"),
         senslope = ifelse(Trend_Aziz.2003 %in% c("Increasing", "Decreasing"), senslope, "NA"),
         rate_per_year = ifelse(Trend_Aziz.2003 %in% c("Increasing", "Decreasing"), rate_per_year, "NA"),
         INTERCEPT = ifelse(Trend_Aziz.2003 %in% c("Increasing", "Decreasing"), INTERCEPT, "NA"))
write.csv(mk_summary_all, "output files/5b_Secular Trend Analysis Summary, All and Recent8 data.csv", na = "", row.names = F)

recent_trend_groups <- mk_summary_all %>% 
  filter(!is.na(Trend8_Aziz.2003))
recent_trend_groups <- recent_trend_groups$key

data_analysis <- data_copc_out_adj %>% 
  left_join(summary_SW, by = c("Chemical", "key", "Location")) %>% 
  left_join(mk_summary_all, by = c("Chemical", "key", "Location")) %>% 
  filter(Location != "Pooled Background")
```

## 6a_Interwell Analysis
Generally update annually during the 1st semi-annual event
Interwell analysis not performed on As (ASD supports intrawell at these wells)
***review the decided data distributions***
**review background and lcl datasets for shifts or trends**
```{r}
#Summarise Background (Upgradient) Well Data
{
data_back <- data_copc_out_adj %>% 
  filter(Location %in% background.wells,
         !Chemical %in% upls) %>% 
  select(key, Location, Chemical, sample_date, StatResult_RL, detect_flag, report_result_unit) %>% 
  mutate(category = "Interwell Background Data")

background_summary1 <- data_back %>% 
  group_by(category, Chemical, detect_flag, report_result_unit) %>% 
  summarise(n = n()) %>% 
  spread(detect_flag, n) %>% 
  mutate(No = coalesce(No, 0),
         Yes = coalesce(Yes, 0),
         Background.Sample.Count = sum(No, Yes),
         Background.Percent_NDs = No / Background.Sample.Count * 100,
         Background.Percent_NDs = format(Background.Percent_NDs, digits = 3))
colnames(background_summary1) <- c("category", "Location", "Units", "Non-Detects, n (Interwell Background)", "Detects, n (Interwell Background)",
                                   "Results, n (Interwell Background)", "Percent Non-Detects (Interwell Background)")

background_summary2 <- data_back %>% 
  group_by(category, Chemical, detect_flag) %>%
  summarise(Max = max(StatResult_RL)) %>% 
  spread(detect_flag, Max)
colnames(background_summary2) <- c("category", "Location", "Max Reporting Limit (Interwell Background)", "Max Detected Result (Interwell Background)")

background_summary3 <- data_back %>% 
  group_by(category, Chemical) %>%
  summarise(Mean = mean(StatResult_RL),
            Median = median(StatResult_RL)) 
colnames(background_summary3) <- c("category", "Location", "Mean (Interwell Background)", "Median (Interwell Background)")
}

background_summary <- left_join(background_summary1, background_summary2) %>% 
  left_join(background_summary3) %>% 
  mutate(Chemical = Location) %>% 
  select(-Location)

#Check assumption of normality for pooled background dataset (upgradient wells)
summary_backgroundstats <- NULL
keys <- unique(data_back$Chemical)
# dev.off()
for(k in keys){
  
  k_data <- data_back %>%  
    filter(Chemical == k) 
  n_all <- as.numeric(nrow(k_data))
  n_nd <- as.numeric(nrow(k_data %>%  filter(detect_flag == "No")))
  a <- unique(k_data$Chemical)
  
  #Test for Statistical Outliers in Baseline Data
  rosner_test <- rosnerTest(k_data$StatResult_RL)

  #Test for Normality of Baseline Data - Shapiro Francia
  res <- ShapiroFranciaTest(k_data$StatResult_RL)
    
  #Test for Temporal Stationarity
    minDate <- min(k_data$sample_date)
    
    mk_sub <-   k_data %>% 
      arrange(sample_date) %>% 
      mutate(DateNum = as.numeric(sample_date - minDate + 1))
    
    #Mann Kendall Test (On seasonally adjusted data where applicable)
    mk_test <- MannKendall(mk_sub$StatResult_RL)
    mk_p <- format(mk_test$sl[1], digits = 3)
    
    results_df <- data.frame(
      key = k,
      Site = "Interwell Background Data",
      Chemical = a,
      n_Background = n_all,
      n_nd_Background = n_nd,
      mean_Background = mean(k_data$StatResult_RL),
      sd_Background = sd(k_data$StatResult_RL),
      Rosner.Statistic = paste(rosner_test$statistic, collapse = ", "),
      Rosner.Critical.Value = paste(rosner_test$crit.value, collapse = ", "),
      Rosner.Alt.Hyp = paste(rosner_test$alternative, collapse = ", "),
      WStatistic.ShapiroFrancia = res$statistic,
      PValue.ShapiroFrancia = res$p.value,
      Distribution = ifelse(res$p.value > 0.05, "Normal (Interwell Background)", "Not normal (Interwell Background)"),
      mk_Score = format(mk_test$S[1], digits = 3),
      mk_conf.factor = format((1 - (as.numeric(mk_p)))*100  , digits = 3),
      COV = format(sd(mk_sub$StatResult_RL, na.rm=TRUE) / 
                    mean(mk_sub$StatResult_RL, na.rm=TRUE), digits = 3))
    results_df <- results_df %>% 
      mutate(Background.Trend_Aziz.2003 = ifelse(is.na(as.numeric(mk_conf.factor)), 
                                               "All tied values (p is NaN).",
                                               ifelse(n_Background == n_nd_Background, "All non-detect results.",
                                               ifelse(as.numeric(mk_Score) > 0 & as.numeric(mk_conf.factor) > 95, "Increasing",
                                                ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) >= 90 & as.numeric(mk_conf.factor) <= 95, 
                                                       "Probably Increasing",
                                                       ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) < 90, 
                                                              "No Trend",
                                                              ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) >= 1, 
                                                                     "No Trend",
                                                                     ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) < 1,
                                                                            "Stable",
                                                                            ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) >= 90 & 
                                                                                     as.numeric(mk_conf.factor) <= 95, 
                                                                                   "Probably Decreasing",
                                                                                   ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) > 95, 
                                                                                          "Decreasing",
                                                                                          "ERROR. Condition not found"))))))))),
             Transformation = "NA - Original Data",
             `Tolerance Interval Analysis` = ifelse(Distribution == "Normal (Interwell Background)", "Parametric (Original Data)", "Non-Parametric (Original Data)"))
    
##
summary_backgroundstats <- bind_rows(results_df, summary_backgroundstats)

#Graphics for final check
{
  # dev.off()
  # create jpeg
  chem <- gsub("& ", "", k)
  chem <- gsub(", ", " ", chem)
  jpeg(paste0("output files/6a_Background/", chem, ".jpg"), width = 17, height = 11, units = "in", res = 300)
  
    # Set up a 2x2 layout for the plots
    par(mfrow = c(2,2))
    
  hist(k_data$StatResult_RL, 
       col = "grey",  # Color of bars
       main = sprintf("\nNormalizing Transformation = NA - Original Data\nHistogram for %s in Interwell Background Data (Upgradient Wells)",  k), # Main title
       xlab = paste0(k, ", ", k_data$report_result_unit[1]),  # X-axis label
       ylab = "Frequency",  # Y-axis label
       sub = sprintf("Non-detects = %s out of %s. ND = RL. Data Transformation: NA - Original Data.", n_nd, n_all),
       col.sub = "blue")
  
    unique_levels <- sort(unique(k_data$detect_flag))

  qq_plot <- 
    {qqnorm(k_data$StatResult_RL, 
            ylab = paste0(k, ", ", k_data$report_result_unit[1]), 
            main = sprintf("\nNormal QQ Plot for %s (%s)", k , k_data$report_result_unit[1]),
            col = ifelse(k_data$detect_flag == "Yes", "black", ifelse(k_data$detect_flag == "No", "grey", "red")), 
            pch = 1, 
            frame = TRUE,
            sub = sprintf("Data Distribution: %s", results_df$Distribution),
            col.sub = "blue")
      
      qqline(k_data$StatResult_RL, col = "skyblue")
      
      #Add legend for detect vs non-detect
      if(length(unique_levels) > 1) {
        legend("topleft", legend = unique_levels, 
               col = c("grey", "black"), 
               pch = 1, title = "Detection Status")
      } else if(unique_levels == "N") {
        legend("topleft", legend = unique_levels, 
               col = "grey", 
               pch = 1, title = "Detection Status") 
      } else if(unique_levels == "Y") {
        legend("topleft", legend = unique_levels, 
               col = "black", 
               pch = 1, title = "Detection Status") 
      }
    }
  
  ###3. TIME SERIES PLOT###
 
      time_series <- 
        ggplot() +
      
        #DATA
        geom_line(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL, color = Location)) +  # Line+
        geom_point(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL, 
                       color = Location, shape = detect_flag)) +  # Point
      
    
        #SCALES & THEME#
        scale_shape_manual(values = c("Yes" = 16, "No" = 1))+
        scale_color_grey()+
        scale_x_date(breaks = date_breaks("1 year"), labels = date_format("%Y")) +
        ggplot2::labs(
          title = "Time Series",  # Main title
          x = "Sample Date",  # X-axis label
          size = "",
          color = "Location", 
          shape = "Detection Status",
          y = sprintf("%s (%s)", k, k_data$report_result_unit[1])
        ) +
        theme_bw() + # Minimal theme for a cleaner look
        theme(legend.position = "top",
              legend.justification = c(0, 1), # Legend position in the upper left corner
              legend.box.margin = margin(-10,-10,-10,-10),
              legend.text = element_text(size = 8),
              legend.title = element_text(size = 8),
              plot.title = element_text(face = "bold", hjust = 0.5),
              plot.caption = element_text(color = "blue", hjust = 0)
              
        )

    vp.BottomRight <- viewport(height=unit(.5, "npc"), width=unit(0.5, "npc"), 
                               just=c("left","top"), 
                               y=0.5, x=0.5)
    
    # plot the ggplot using the print command
    print(time_series, vp=vp.BottomRight)
  
    
     box_plot <-
       ggplot(data = k_data) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "red",
                   outlier.shape = 5,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )
      vp.BottomLeft <- viewport(height=unit(0.5, "npc"), width=unit(0.5, "npc"), 
                              just=c("left","top"), 
                              y=0.5, x=0)
    
    # plot the ggplot using the print command
    print(box_plot, vp=vp.BottomLeft)
    
  dev.off()
}
    

}
write.csv(summary_backgroundstats, "output files/7a_Interwell Background Data Summary_Original Data.csv")

normality_test <- NULL
for (k in keys){
  
k_data <- data_back %>%  
    filter(Chemical == k) 
  
# Define a list of transformations to test
transformations <- list(
  original = k_data$StatResult_RL,
  ln = log(k_data$StatResult_RL),  # Adding 1 to avoid taking log of zero
  log10 = log10(k_data$StatResult_RL),  # Adding 1 to avoid taking log of zero
  sqrt = sqrt(k_data$StatResult_RL),
  cube_root = sign(k_data$StatResult_RL) * abs(k_data$StatResult_RL)^(1/3),  # Cube root with sign preserved
  square = k_data$StatResult_RL^2,
  reciprocal = 1 / k_data$StatResult_RL
  # Add more transformations as needed
)

# Perform Shapiro-Wilk test for each transformation
normality_results <- lapply(transformations, function(x) ShapiroFranciaTest(x)$p.value)

# Print the results
names(normality_results) <- c("Original", "Natural Log", "Log10", "Square Root", "Cube Root", "Square", "Reciprocal")
normality_results <- as.data.frame(normality_results) %>% 
  mutate(Chemical = k,
         category = "Interwell Background Data")

normality_test <- bind_rows(normality_test, normality_results)
}
write.csv(normality_test, "output files/7b_Normality Check_Transformed Data Shapiro Wilk Results.csv")

normality_test_eval <- normality_test %>% 
  melt(c(8:9)) %>% 
  mutate(Distribution = ifelse(value > 0.05, "Normal", "Not Normal")) %>% 
  select(-value) %>% 
  spread(variable, Distribution) %>% 
  left_join(background_summary, by = "Chemical") %>% 
  mutate(Selected.Distribution = ifelse(Original == "Normal", "Parametric_Original Data",
                                        ifelse(as.numeric(`Percent Non-Detects (Interwell Background)`) > 50, "Non-Parametric",
                                        ifelse(Natural.Log == "Normal", "Parametric (lognormal trans)",
                                               ifelse(Log10 == "Normal", "Parametric_log10",
                                                      ifelse(Square.Root == "Normal", "Parametric_sqrt",
                                                             ifelse(Cube.Root == "Normal", "Parametric_cbrt",
                                                                    ifelse(Square == "Normal", "Parametric_sq",
                                                                           ifelse(Reciprocal == "Normal", "Parametric_reciprocal",
                                                                                 "Non-Parametric"
                                                                          )))))))))
write.csv(normality_test_eval, "output files/7c_Normality Check.csv")

#UPDATE TO INCORPORATE PARAMETRIC AND LOGNORMAL TRANS PARAMETRIC CALCS
summary_backgroundstats_selected <- NULL
keys <- unique(data_back$Chemical)

unique(normality_test_eval$Selected.Distribution)
for(k in keys){
  k_data <- data_back %>%  
    filter(Chemical == k) 
  
  n_all <- as.numeric(nrow(k_data))
  n_nd <- as.numeric(nrow(k_data %>%  filter(detect_flag == "No")))
  a <- unique(k_data$Chemical)
  
  d <- normality_test_eval %>%  
    filter(Chemical == k)
  d <- d$Selected.Distribution

  if(d == "Non-Parametric"){
  
  UTL.data <- k_data %>% 
    arrange(desc(StatResult_RL)) %>%
    slice(1)
  UTL <- UTL.data$StatResult_RL
  UTL_Detection.Status <- UTL.data$detect_flag
 
  tol.int.test <-  tolIntNpar(k_data$StatResult_RL, 
      conf.level = 0.95, lb = 0, ti.type = "upper")

  #Test for Statistical Outliers in Baseline Data
  rosner_test <- rosnerTest(k_data$StatResult_RL)

  #Test for Normality of Baseline Data
  res <- ShapiroFranciaTest(k_data$StatResult_RL)
  
    
  #Test for Temporal Stationarity
    minDate <- min(k_data$sample_date)
    
    mk_sub <-   k_data %>% 
      arrange(sample_date) %>% 
      mutate(DateNum = as.numeric(sample_date - minDate + 1))
    
    #Mann Kendall Test (On seasonally adjusted data where applicable)
    mk_test <- MannKendall(mk_sub$StatResult_RL)
    mk_p <- format(mk_test$sl[1], digits = 3)
    
    
    results_df <- data.frame(
      key = k,
      Site = "Interwell Background Data",
      Chemical = a,
      n_Background = n_all,
      n_nd_Background = n_nd,
      mean_Background = mean(k_data$StatResult_RL),
      sd_Background = sd(k_data$StatResult_RL),
      Rosner.Statistic = paste(rosner_test$statistic, collapse = ", "),
      Rosner.Critical.Value = paste(rosner_test$crit.value, collapse = ", "),
      Rosner.Alt.Hyp = paste(rosner_test$alternative, collapse = ", "),
      WStatistic.ShapiroFrancia = res$statistic,
      PValue.ShapiroFrancia = res$p.value,
      Distribution = d,
      mk_Score = format(mk_test$S[1], digits = 3),
      mk_conf.factor = format((1 - (as.numeric(mk_p)))*100  , digits = 3),
      COV = format(sd(mk_sub$StatResult_RL, na.rm=TRUE) / 
                    mean(mk_sub$StatResult_RL, na.rm=TRUE), digits = 3))
    results_df <- results_df %>% 
      mutate(Background.Trend_Aziz.2003 = ifelse(is.na(as.numeric(mk_conf.factor)), 
                                               "All tied values (p is NaN).",
                                               ifelse(n_Background == n_nd_Background, "All non-detect results.",
                                                      ifelse(n_nd_Background > 0.5*n_Background, "More than 50% NDs",
                                               ifelse(as.numeric(mk_Score) > 0 & as.numeric(mk_conf.factor) > 95, "Increasing",
                                                ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) >= 90 & as.numeric(mk_conf.factor) <= 95, 
                                                       "Probably Increasing",
                                                       ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) < 90, 
                                                              "No Trend",
                                                              ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) >= 1, 
                                                                     "No Trend",
                                                                     ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) < 1,
                                                                            "Stable",
                                                                            ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) >= 90 & 
                                                                                     as.numeric(mk_conf.factor) <= 95, 
                                                                                   "Probably Decreasing",
                                                                                   ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) > 95, 
                                                                                          "Decreasing",
                                                                                          "ERROR. Condition not found")))))))))),
             Transformation = "NA - Original Data",
             UTL.Method = "Non-Parametric Tolerance Limits (USEPA, 2009 - Chapter 17.2.2)",
             UTL.Method.Detail = "Maximum Value (ND = RL, Non-discriminatory of detection status)",
             UTL = UTL,
             UTL.full =as.character(tol.int.test$interval[5]),
             `UTL Detection Status` = UTL_Detection.Status,
             `Minimum Coverage (%)` = format(as.numeric(tol.int.test$interval[2])*100, digits = 3))
    
summary_backgroundstats_selected <- bind_rows(results_df, summary_backgroundstats_selected)

{
               
    #PARAMETRIC ORIGINAL DATA - AT THIS TIME NOT APPLICABLE TO ANY COIs
    # } else if("") {
#     
# 
#   #Test for Statistical Outliers in Baseline Data
#   rosner_test <- rosnerTest(k_data$StatResult_RL)
# 
#   #Test for Normality of Baseline Data
#   res <- ShapiroFranciaTest(k_data$StatResult_RL)
#     
#   #Test for Temporal Stationarity
#     minDate <- min(k_data$sample_date)
#     
#     mk_sub <-   k_data %>% 
#       arrange(sample_date) %>% 
#       mutate(DateNum = as.numeric(sample_date - minDate + 1))
#     
#     #Mann Kendall Test (On seasonally adjusted data where applicable)
#     mk_test <- MannKendall(mk_sub$StatResult_RL)
#     mk_p <- format(mk_test$sl[1], digits = 3)
#     
#     
#     results_df <- data.frame(
#       key = k,
#       Site = "Interwell Background Data",
#       Chemical = a,
#       n_Background = n_all,
#       n_nd_Background = n_nd,
#       mean_Background = mean(k_data$StatResult_RL),
#       sd_Background = sd(k_data$StatResult_RL),
#       Rosner.Statistic = paste(rosner_test$statistic, collapse = ", "),
#       Rosner.Critical.Value = paste(rosner_test$crit.value, collapse = ", "),
#       Rosner.Alt.Hyp = paste(rosner_test$alternative, collapse = ", "),
#       WStatistic.ShapiroFrancia = res$statistic,
#       PValue.ShapiroFrancia = res$p.value,
#       Distribution = ifelse(res$p.value > 0.05, "Normal (Interwell Background)", "Not normal (Interwell Background)"),
#       mk_Score = format(mk_test$S[1], digits = 3),
#       mk_conf.factor = format((1 - (as.numeric(mk_p)))*100  , digits = 3),
#       COV = format(sd(mk_sub$StatResult_RL, na.rm=TRUE) / 
#                     mean(mk_sub$StatResult_RL, na.rm=TRUE), digits = 3))
#     results_df <- results_df %>% 
#       mutate(Background.Trend_Aziz.2003 = ifelse(is.na(as.numeric(mk_conf.factor)), 
#                                                "All tied values (p is NaN).",
#                                                ifelse(n_Background == n_nd_Background, "All non-detect results.",
#                                                ifelse(as.numeric(mk_Score) > 0 & as.numeric(mk_conf.factor) > 95, "Increasing",
#                                                 ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) >= 90 & as.numeric(mk_conf.factor) <= 95, 
#                                                        "Probably Increasing",
#                                                        ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) < 90, 
#                                                               "No Trend",
#                                                               ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) >= 1, 
#                                                                      "No Trend",
#                                                                      ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) < 1,
#                                                                             "Stable",
#                                                                             ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) >= 90 & 
#                                                                                      as.numeric(mk_conf.factor) <= 95, 
#                                                                                    "Probably Decreasing",
#                                                                                    ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) > 95, 
#                                                                                           "Decreasing",
#                                                                                           "ERROR. Condition not found"))))))))),
#              Transformation = "NA - Original Data",
#              UTL.Method = "Parametric Tolerance Limits (USEPA, 2009 - Chapter 17.2.1)",
#              UTL.Method.Detail = "Background mean + K * Background Standard Deviation",
#              `One-sided normal tolerance factor (K) at 95% coverage and 95% probability` =   
#                tolIntNormK(n_Background, df = n_Background - 1, coverage = 0.95, cov.type = "content", 
#                            ti.type = "upper", conf.level = 0.95, method = "exact", 
#                            rel.tol = 0.0000001, abs.tol = 0.0000001),
#              UTL = (mean_Background + `One-sided normal tolerance factor (K) at 95% coverage and 95% probability` * sd_Background))
#
      }
    } else if(d == "Parametric (lognormal trans)") {

k_data <- k_data %>%
   mutate(StatResult_RLln = log(StatResult_RL))
      #Test for Statistical Outliers in Baseline Data
rosner_test <- rosnerTest(k_data$StatResult_RLln)

#Test for Normality of Baseline Data
res <- ShapiroFranciaTest(k_data$StatResult_RLln)

#Test for Temporal Stationarity
  minDate <- min(k_data$sample_date)

  mk_sub <-   k_data %>%
    arrange(sample_date) %>%
    mutate(DateNum = as.numeric(sample_date - minDate + 1))

  #Mann Kendall Test (On seasonally adjusted data where applicable)
  mk_test <- MannKendall(mk_sub$StatResult_RL)
  mk_p <- format(mk_test$sl[1], digits = 3)


  results_df <- data.frame(
    key = k,
    Site = "Interwell Background Data",
    Chemical = a,
    n_Background = n_all,
    n_nd_Background = n_nd,
    mean_Backgroundln = mean(k_data$StatResult_RLln),
    sd_Backgroundln = sd(k_data$StatResult_RLln),
        mean_Background = mean(k_data$StatResult_RL),
    sd_Background = sd(k_data$StatResult_RL),
    Rosner.Statistic = paste(rosner_test$statistic, collapse = ", "),
    Rosner.Critical.Value = paste(rosner_test$crit.value, collapse = ", "),
    Rosner.Alt.Hyp = paste(rosner_test$alternative, collapse = ", "),
    WStatistic.ShapiroFrancia = res$statistic,
    PValue.ShapiroFrancia = res$p.value,
    Distribution = d,
    mk_Score = format(mk_test$S[1], digits = 3),
    mk_conf.factor = format((1 - (as.numeric(mk_p)))*100  , digits = 3),
    COV = format(sd(mk_sub$StatResult_RL, na.rm=TRUE) /
                  mean(mk_sub$StatResult_RL, na.rm=TRUE), digits = 3))
  
  results_df <- results_df %>%
    mutate(Background.Trend_Aziz.2003 = ifelse(is.na(as.numeric(mk_conf.factor)),
                                             "All tied values (p is NaN).",
                                             ifelse(n_Background == n_nd_Background, "All non-detect results.",
                                                    ifelse(n_nd_Background > 0.5*n_Background, "More than 50% NDs",
                                             ifelse(as.numeric(mk_Score) > 0 & as.numeric(mk_conf.factor) > 95, "Increasing",
                                              ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) >= 90 & as.numeric(mk_conf.factor) <= 95,
                                                     "Probably Increasing",
                                                     ifelse(as.numeric(mk_Score)  > 0 & as.numeric(mk_conf.factor) < 90,
                                                            "No Trend",
                                                            ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) >= 1,
                                                                   "No Trend",
                                                                   ifelse(as.numeric(mk_Score)  <= 0 & as.numeric(mk_conf.factor) < 90 & as.numeric(COV) < 1,
                                                                          "Stable",
                                                                          ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) >= 90 &
                                                                                   as.numeric(mk_conf.factor) <= 95,
                                                                                 "Probably Decreasing",
                                                                                 ifelse(as.numeric(mk_Score)  < 0 & as.numeric(mk_conf.factor) > 95,
                                                                                        "Decreasing",
                                                                                        "ERROR. Condition not found")))))))))),
           Transformation = "Natural Logarithm",
           UTL.Method = "Parametric Tolerance Limits (USEPA, 2009 - Chapter 17.2.1)",
           UTL.Method.Detail = "Background mean + K * Background Standard Deviation",
           `Minimum Coverage (%)` = format(as.numeric(0.95)*100, digits = 3),
           `One-sided normal tolerance factor (K) at 95% coverage and 95% probability` =
             tolIntNormK(n_Background, df = n_Background - 1, coverage = 0.95, cov.type = "content",
                         ti.type = "upper", conf.level = 0.95, method = "exact",
                         rel.tol = 0.0000001, abs.tol = 0.0000001),
           UTL = exp(mean_Backgroundln + `One-sided normal tolerance factor (K) at 95% coverage and 95% probability` * sd_Backgroundln)) %>% 
    select(-mean_Backgroundln, -sd_Backgroundln)
  
summary_backgroundstats_selected <- bind_rows(results_df, summary_backgroundstats_selected)

    }


#Graphics for final check
{
  #dev.off()
  #create jpeg
  k_data <- k_data %>% 
  mutate(k_data = ifelse(d == "Parametric (lognormal trans)",
                         log(StatResult_RL), StatResult_RL))
  jpeg(paste0("output files/6a_Background/", k, "_UTLs.jpg"), width = 17, height = 11, units = "in", res = 300)
  
    # Set up a 2x2 layout for the plots
    par(mfrow = c(2,2))
    
  hist(k_data$StatResult_RL, 
       col = "grey",  # Color of bars
       main = sprintf("\nNormalizing Transformation = %s\nHistogram for %s in Interwell Background Data (Upgradient Wells)",results_df$Transformation,  k), # Main title
       xlab = paste0(k, ", ", k_data$report_result_unit[1]),  # X-axis label
       ylab = "Frequency",  # Y-axis label
       sub = sprintf("Non-detects = %s out of %s. ND = RL. Data Transformation: %s.", n_nd, n_all, results_df$Transformation),
       col.sub = "blue")
  
    unique_levels <- sort(unique(k_data$detect_flag))

  qq_plot <- 
    {qqnorm(k_data$StatResult_RL, 
            ylab = paste0(k, ", ", k_data$report_result_unit[1]), 
            main = sprintf("\nNormal QQ Plot for %s (%s)", k , k_data$report_result_unit[1]),
            col = ifelse(k_data$detect_flag == "Yes", "black", ifelse(k_data$detect_flag == "No", "grey", "red")), 
            pch = 1, 
            frame = TRUE,
            sub = sprintf("Data Distribution: %s", results_df$Distribution),
            col.sub = "blue")
      
      qqline(k_data$StatResult_RL, col = "skyblue")
      
      #Add legend for detect vs non-detect
      if(length(unique_levels) > 1) {
        legend("topleft", legend = unique_levels, 
               col = c("grey", "black"), 
               pch = 1, title = "Detection Status")
      } else if(unique_levels == "N") {
        legend("topleft", legend = unique_levels, 
               col = "grey", 
               pch = 1, title = "Detection Status") 
      } else if(unique_levels == "Y") {
        legend("topleft", legend = unique_levels, 
               col = "black", 
               pch = 1, title = "Detection Status") 
      }
    }
  
  ###3. TIME SERIES PLOT###
 
      time_series <- 
        ggplot() +
      
        #DATA
        geom_line(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL, color = Location)) +  # Line+
        geom_point(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL, 
                       color = Location, shape = detect_flag)) +  # Point
        geom_hline(aes(yintercept = as.numeric(results_df$UTL)), color = "goldenrod")+
        geom_text(aes(y = as.numeric(results_df$UTL), x = as.Date("2023-01-01")), color = "goldenrod", label = "UTL", vjust = 0.5)+
    
        #SCALES & THEME#
        scale_shape_manual(values = c("Yes" = 16, "No" = 1))+
        scale_color_grey()+
        scale_x_date(breaks = date_breaks("1 year"), labels = date_format("%Y")) +
        ggplot2::labs(
          title = "Time Series",  # Main title
          x = "Sample Date",  # X-axis label
          size = "",
          color = "Location", 
          shape = "Detection Status",
          y = sprintf("%s (%s)", k, k_data$report_result_unit[1]) , # Y-axis label
          caption = sprintf("Normalizing Data Transformation = %s; UTL Method = %s,\n%s; UTL = %s\nTrend Identified in Background Data (Aziz, 2003) = %s", results_df$Transformation, results_df$UTL.Method, results_df$UTL.Method.Detail, results_df$UTL, results_df$Background.Trend_Aziz.2003)
        ) +
        theme_bw() + # Minimal theme for a cleaner look
        theme(legend.position = "top",
              legend.justification = c(0, 1), # Legend position in the upper left corner
              legend.box.margin = margin(-10,-10,-10,-10),
              legend.text = element_text(size = 8),
              legend.title = element_text(size = 8),
              plot.title = element_text(face = "bold", hjust = 0.5),
              plot.caption = element_text(color = "blue", hjust = 0)
              
        )

    vp.BottomRight <- viewport(height=unit(.5, "npc"), width=unit(0.5, "npc"), 
                               just=c("left","top"), 
                               y=0.5, x=0.5)
    
    # plot the ggplot using the print command
    print(time_series, vp=vp.BottomRight)
  
    
     box_plot <-
       ggplot(data = k_data) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "red",
                   outlier.shape = 5,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )
      vp.BottomLeft <- viewport(height=unit(0.5, "npc"), width=unit(0.5, "npc"), 
                              just=c("left","top"), 
                              y=0.5, x=0)
    
    # plot the ggplot using the print command
    print(box_plot, vp=vp.BottomLeft)
    
  dev.off()
}
    
}
write.csv(summary_backgroundstats_selected, "output files/7d_UTL Calculations and Background Data Evaluation.csv")

```

## 6a_Intrawell Analysis (Arsenic in Downgradient Wells)
check for UPL updates
```{r}

check <- data_copc_out_adj %>% 
  filter(sample_date > UPL.Update.Date) %>% 
  group_by(Location, Chemical) %>% 
  summarise(n = n()) %>% 
  filter(n < 4)
if(nrow(check > 0)){ "Do not update all" }else{ "Update all"}
   
```

test whether it's statistically justifiable to update baseline
```{r}
# Subset and label baseline data
old.baseline <- data_stats %>%
  filter(Chemical %in% upls, Location %in% downgradient,
         sample_date < old.UPL.date) %>%
  mutate(group = "Existing baseline")

new.baseline <- data_stats %>%
  filter(Chemical %in% upls, Location %in% downgradient,
         sample_date > old.UPL.date, sample_date < UPL.Update.Date) %>%
  mutate(group = "New baseline")

# Combine datasets
combined <- bind_rows(old.baseline, new.baseline)

# Loop over each chemical to test variance and mean similarity
comparison_results <- combined %>%
  group_by(Chemical, Location) %>%
  group_modify(~ {
    data <- .
    
    # Levene's test for equal variances
    p_levene <- tryCatch(
      leveneTest(StatResult_RL ~ group, data = data)$`Pr(>F)`[1],
      error = function(e) NA
    )
    
    # Non-parametric test (Wilcoxon rank-sum test)
    p_wilcox <- tryCatch(
      wilcox.test(StatResult_RL ~ group, data = data)$p.value,
      error = function(e) NA
    )
    
    tibble(
      p_levene = p_levene,
      p_wilcox = p_wilcox,
    )
  }) %>%
  ungroup()

# Flag whether variance and mean are similar (p > 0.05)
results <- comparison_results %>%
  mutate(
    Variance_Similar = p_levene > 0.05,
    Mean_Similar = p_wilcox > 0.05,
    Recommend_Update = Variance_Similar | Mean_Similar
  )
write.csv(results, "output files/6a_Intrawell update levene test results.csv")

if(nrow(results %>% filter(Recommend_Update == "FALSE"))>0){ "FURTHER INSPECTION NEEDED PRIOR TO BASELINE UPDATE, CHANGE IN DATA"} else { "UPDATE ALL"}

#Haven't coded yet what to do if false...if false, then the stats prof needs to review the data and decide to either update despite differences in variance and central tendencies, OR do not update this event and put off the update until data stabilize. Look at time series for all appx III and IV constituents (plots at end of code, ggplotly)
# Point of this exercise is to avoid updating baseline datasets that may be influenced by CCR
```


```{r}

data_baseline <- NULL

for(d in downgradient){
  for (c in upls){
data_base <- data_copc_out_adj %>% 
  filter(Chemical == c,
         Location == d,
         sample_date < UPL.Update.Date) %>% 
  select(key, Location, Chemical, sample_date, StatResult_RL, StatResult_0.5RL, detect_flag, report_result_unit) %>% 
  arrange(desc(sample_date)) %>% 
  mutate(category = "Baseline Data") 

data_baseline <- bind_rows(data_baseline, data_base)
  }
}

upl.baseline_date <- data_baseline %>% 
  filter(category == "Baseline Data") %>% 
  group_by(key) %>% 
  summarise(min_date = min(sample_date),
            max_date = max(sample_date))
upl.compliance_date <- data_baseline %>% 
  filter(category == "Compliance Data") %>% 
  group_by(key) %>% 
  summarise(min_datec = min(sample_date),
            max_datec = max(sample_date))
#Re-run shapiro wilk test for normality on baseline data to determine distribution of baseline data (previously done for entire dataset)
summary_Baseline <- NULL
keys <- unique(data_baseline$key)

for(k in keys){
  
  k_data <- data_baseline %>%  
    filter(key == k,
           category == "Baseline Data") %>% 
    mutate(StatResult_0.5RL_ln = log(StatResult_0.5RL))
  
  n_all <- as.numeric(nrow(k_data))
  n_nd <- as.numeric(nrow(k_data %>%  filter(detect_flag == "No")))
  l <- unique(k_data$Location)
  a <- unique(k_data$Chemical)
  
  #Test for Normality of Baseline Data
    res <- shapiro.test(k_data$StatResult_0.5RL)
      res.ln <- shapiro.test(k_data$StatResult_0.5RL_ln)
      
    #Pull trend from previous testing
    trend <- mk_summary_all %>% 
      filter(key == k) %>% 
      pull(Trend_Aziz.2003)
    
    results_df <- data.frame(
      key = k,
      Site = "Baseline Data",
      Location = l,
      Chemical = a,
      n_Baseline = n_all,
      n_nd_Baseline = n_nd,
      mean_Baseline = mean(k_data$StatResult_RL),
      sd_Baseline = sd(k_data$StatResult_RL),
      WStatistic.SW = res$statistic,
      PValue.SW = res$p.value,
      Distribution.95 = ifelse(res$p.value > 0.01, "Normal", "Not normal"),
      Distribution.99 = ifelse(res$p.value > 0.01, "Normal", "Not normal"),
      WStatistic.SW.ln = res.ln$statistic,
      PValue.SW.ln = res.ln$p.value,
      Distribution.95.ln = ifelse(res.ln$p.value > 0.01, "Lognormal", "Not Lognormal"),
      Distribution.99.ln = ifelse(res.ln$p.value > 0.01, "Lognormal", "Not Lognormal"),
      trend = trend)
    
    summary_Baseline <- bind_rows(results_df, summary_Baseline)
    
}

write.csv(summary_Baseline, "output files/6a_Background/7_baseline data distribution.csv", row.names = F)

ggplot(data = data_baseline %>%  
         left_join(summary_Baseline) %>%  
         filter(category == "Baseline Data"), 
       aes(sample = StatResult_RL, color = Distribution.99, shape = category))+
  geom_qq() +
  stat_qq_line() + # Add a diagonal reference line
  labs(title = "Q-Q Plot", x = "Theoretical Quantiles", y = "Sample Quantiles")+
  theme(aspect.ratio  =1)+
  # facet_grid(rows = vars(Chemical), col = vars(Location), scales = "free")
  facet_wrap(~key, scales = "free")

ggsave("output files/6a_Background/Intrawell QQ plots.png", height = 11, width = 17)

ggplot(data = data_baseline %>%  left_join(summary_Baseline), 
       aes(sample = log(StatResult_RL), color = Distribution.99.ln, shape = Distribution.95.ln))+
  geom_qq() +
  stat_qq_line() + # Add a diagonal reference line
  labs(title = "Q-Q Plot", x = "Theoretical Quantiles", y = "Natural Log Sample Quantiles")+
  theme(aspect.ratio  =1)+
  facet_wrap(~key, scales = "free")
ggsave("output files/6a_Background/Intrawell UPLs QQ plots, natural log transform.png", height = 11, width = 17)

ggplot(data = combined,
       aes(y = StatResult_RL, x = sample_date, color = group))+
  geom_point(aes(shape = detect_flag)) +
  geom_line()+
  labs(title = "Time Series Baseline DAta", x = "sample date", y = "Concentration (mg/L)")+
  facet_wrap(~key, scales = "free")
ggsave("output files/6a_Background/Intrawell Time Series plots.png", height = 11, width = 17)

##compile final info for UPL analysis
summary_Baseline_selected <- summary_Baseline %>% 
  mutate(selected_distribution = ifelse(n_nd_Baseline > 0.5*n_Baseline, "Non-Parametric",
                                        ifelse(Distribution.99 == "Normal", "Normal",
                                               ifelse(Distribution.99.ln == "Lognormal", "Lognormal",
                                                      "Non-Parametric"))),
    `Prediction Interval Calculation Method` = 
           ifelse(selected_distribution == "Normal", "Parametric",
                  ifelse(selected_distribution == "Lognormal",
                         "Parametric (ln Transform)",
                         "Non-Parametric")))
write.csv(summary_Baseline_selected, "output files/7a_Intrawell UPL Baseline data distributions.csv")


baseline_data_UPLs <- data_baseline %>% 
  left_join(summary_Baseline_selected) %>% 
  mutate(StatResult_Baseline = ifelse(selected_distribution == "Normal (Baseline, ln Trans, 99% Confidence)", log(StatResult_RL),
                                      StatResult_RL)) 
write.csv(baseline_data_UPLs, "output files/7a_UPL Baseline input data_transformed as applicable.csv")


Intrawell.Baseline <- baseline_data_UPLs %>% 
  filter(category == "Baseline Data") %>% 
  group_by(key, Location, Chemical, report_result_unit, selected_distribution, `Prediction Interval Calculation Method`, n_nd_Baseline) %>% 
  summarise(Intrawell.Baseline.n = as.numeric(n()),
            Intrawell.Baseline.max = max(StatResult_RL),
            Intrawell.Baseline.mean = mean(StatResult_Baseline),
            Intrawell.Baseline.sd = sd(StatResult_Baseline),
            Degrees.of.freedom = as.numeric(Intrawell.Baseline.n - 1),
            Compliance.n = as.numeric(n()),
            Confidence.Level_pct = (1 - (0.01/Compliance.n))*100,
            t = format(as.numeric(1 - 0.01 / 4), digits = 4)) #99% One Sided Comparison

UPL.Calcs <- Intrawell.Baseline %>% 
  mutate(t_quantile = qt(as.numeric(t), Degrees.of.freedom), #ChemStats t_quantile differs from standard t-dist quantile charts by USEPA.
         Intrawell.UPL = ifelse(`Prediction Interval Calculation Method` != "Non-Parametric", 
                                Intrawell.Baseline.mean + t_quantile * 
                                Intrawell.Baseline.sd * sqrt(1 + (1/Intrawell.Baseline.n)), #Parametric calc
                                Intrawell.Baseline.max), #Non-parametric order stat
         Intrawell.UPL.Untransformed = ifelse(`Prediction Interval Calculation Method` == "Parametric (ln Transformed Data)", #Untransform UPL calculated from transformed data
                                              exp(Intrawell.UPL), Intrawell.UPL),
         Intrawell.UPL.Method = ifelse(`Prediction Interval Calculation Method` != "Non-Parametric",
                                       "Parametric Prediction Limit for M Future Values (USEPA, 2009 - Chapter 18.2.1)", 
                                       "Non-Parametric Prediction Limit for M Future Values (USEPA, 2009 - Chapter 18.3.1)"),
         `Confidence.Level (%) for Non-Parametric UPL(s)` = ifelse(`Prediction Interval Calculation Method` == "Non-Parametric",
                                                                   Intrawell.Baseline.n / (Intrawell.Baseline.n + Compliance.n) *100, 
                                                                   NA),
         `False Positive Rate (%) for Non-Parametric UPL(s)` = ifelse(`Prediction Interval Calculation Method` == "Non-Parametric",
                                                                      100-`Confidence.Level (%) for Non-Parametric UPL(s)`, 
                                                                      NA),
         UPL.Update = sprintf("%s", Event)) %>% 
  left_join(baseline_data_UPLs %>% filter(category == "Baseline Data") %>% 
              select(c(1:3, trend, selected_distribution)) %>%
              distinct())

UPL.Calcs <- as.data.frame(UPL.Calcs) %>% 
    mutate(Confidence.Level_pct = ifelse(Intrawell.UPL.Method == "Non-Parametric Prediction Limit for M Future Values (USEPA, 2009 - Chapter 18.3.1)", NA, Confidence.Level_pct),
         t = ifelse(Intrawell.UPL.Method == "Non-Parametric Prediction Limit for M Future Values (USEPA, 2009 - Chapter 18.3.1)",NA, t),
         t_quantile = ifelse(Intrawell.UPL.Method == "Non-Parametric Prediction Limit for M Future Values (USEPA, 2009 - Chapter 18.3.1)", NA, t_quantile))
write.csv(UPL.Calcs, "output files/7b_UPL Calcs.csv")


UPL_Comparisons <- left_join(UPL.Calcs, 
                             baseline_data_UPLs %>%  
                               filter(category == "Compliance Data"), multiple = "all") %>% 
  mutate(UPL_Exceedance = ifelse(StatResult_RL > Intrawell.UPL.Untransformed, "Yes", "No")) 
write.csv(UPL_Comparisons, "output files/7c_UPL Comparison for Compliance Data.csv")

#GRAPHICS FOR FINAL CHECK
for (k in keys){

  k_data <- data_baseline %>%  
    filter(key == k)
  results_df_Sub <- UPL.Calcs %>% 
    filter(key == k)
  n_nd <- nrow(k_data %>% filter(detect_flag == "No"))
  n_all <- nrow(k_data)
  trend <- mk_summary_all %>% filter(key == k) %>% pull(Trend_Aziz.2003)
  #create jpeg
  jpeg(paste0("output files/6a_Background/Intrawell Background Data for ", k, "_UPLs.jpg"), width = 17, height = 11, units = "in", res = 300)
  
    # Set up a 2x2 layout for the plots
    par(mfrow = c(2,2))
    
  hist(k_data$StatResult_RL, 
       col = "grey",  # Color of bars
       main = sprintf("\nHistogram for %s in Intrawell Baseline Data",  k), # Main title
       xlab = paste0(k, ", ", k_data$report_result_unit[1]),  # X-axis label
       ylab = "Frequency",  # Y-axis label
       sub = sprintf("Non-detects = %s out of %s. ND = RL. Data distribution for calculation: %s.", n_nd, n_all, results_df_Sub$selected_distribution),
       col.sub = "blue")
  
    unique_levels <- sort(unique(k_data$detect_flag))

  qq_plot <- 
    {qqnorm(k_data$StatResult_RL, 
            ylab = paste0(k, ", ", k_data$report_result_unit[1]), 
            main = sprintf("\nNormal QQ Plot for %s (%s)", k , k_data$report_result_unit[1]),
            col = ifelse(k_data$detect_flag == "Yes", "black", ifelse(k_data$detect_flag == "No", "grey", "red")), 
            pch = 1, 
            frame = TRUE,
            sub = sprintf("Data Distribution: %s", results_df_Sub$Distribution),
            col.sub = "blue")
      
      qqline(k_data$StatResult_RL, col = "skyblue")
      
      #Add legend for detect vs non-detect
      if(length(unique_levels) > 1) {
        legend("topleft", legend = unique_levels, 
               col = c("grey", "black"), 
               pch = 1, title = "Detection Status")
      } else if(unique_levels == "N") {
        legend("topleft", legend = unique_levels, 
               col = "grey", 
               pch = 1, title = "Detection Status") 
      } else if(unique_levels == "Y") {
        legend("topleft", legend = unique_levels, 
               col = "black", 
               pch = 1, title = "Detection Status") 
      }
    }
  
  ###3. TIME SERIES PLOT###
 
      time_series <- 
        ggplot() +
      
        #DATA
        geom_line(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL)) +  # Line+
        geom_point(data = k_data, 
                  aes(x = sample_date, y = StatResult_RL, 
                       color = category, shape = detect_flag)) +  # Point
        geom_hline(aes(yintercept = as.numeric(results_df_Sub$Intrawell.UPL.Untransformed)),
                   color = "goldenrod")+
        geom_text(aes(y = as.numeric(results_df_Sub$Intrawell.UPL.Untransformed), x = as.Date("2023-01-01")),
                  color = "goldenrod", label = "UPL", vjust = 0.5)+
    
        #SCALES & THEME#
        scale_shape_manual(values = c("Yes" = 16, "No" = 1))+
        scale_color_grey()+
        scale_x_date(breaks = date_breaks("1 year"), labels = date_format("%Y")) +
        ggplot2::labs(
          title = "Time Series",  # Main title
          x = "Sample Date",  # X-axis label
          size = "",
          color = "Location", 
          shape = "Detection Status",
          y = sprintf("%s (%s)", k, k_data$report_result_unit[1]) , # Y-axis label
          caption = sprintf("Trend Identified in Background Data (Aziz, 2003) = %s",  trend)
        ) +
        theme_bw() + # Minimal theme for a cleaner look
        theme(legend.position = "top",
              legend.justification = c(0, 1), # Legend position in the upper left corner
              legend.box.margin = margin(-10,-10,-10,-10),
              legend.text = element_text(size = 8),
              legend.title = element_text(size = 8),
              plot.title = element_text(face = "bold", hjust = 0.5),

        )
time_series
    vp.BottomRight <- viewport(height=unit(.5, "npc"), width=unit(0.5, "npc"), 
                               just=c("left","top"), 
                               y=0.5, x=0.5)
    
    # plot the ggplot using the print command
    print(time_series, vp=vp.BottomRight)
  
    
     box_plot <-
       ggplot(data = k_data) +
      stat_boxplot(aes(x = Location, y = StatResult_RL),
                   geom ='errorbar', width = 0.15) +
      geom_boxplot(aes(x = Location, y = StatResult_RL),
                   fill = "grey",
                   color = "black",
                   outlier.color = "red",
                   outlier.shape = 5,
                   fatten = 2,
                   width = 0.3) +  # Box plot
      scale_color_manual(values = c("No" = "grey", "Yes" = "black")) +
      scale_shape_manual(values = c("Yes" = 16, "No" = 1)) +
      labs(
        title = "Box Plots",  # Main title
        color = "Detection Status:", shape = "Detection Status:",
        y = "Concentration")+
      theme_bw() + # Minimal theme for a cleaner look
      theme(
        legend.position = "top",
        legend.justification = c(1, 1),
        # legend.box.background = element_rect(color = "black"),
        legend.box.margin = margin(-10,-10,-10,-10),
        # aspect.ratio = 1.5,
        legend.text = element_text(size = 8),
        axis.text.x = element_text(angle = -45, hjust = 0),
        legend.title = element_text(size = 8),
        plot.subtitle = element_text(size = 8),
        plot.title = element_text(face = "bold", hjust = 0.5),
        plot.caption = element_text(color = "blue")
      )
      vp.BottomLeft <- viewport(height=unit(0.5, "npc"), width=unit(0.5, "npc"), 
                              just=c("left","top"), 
                              y=0.5, x=0)
    
    # plot the ggplot using the print command
    print(box_plot, vp=vp.BottomLeft)
    
  dev.off()
}

```


##6b_GWPS compilation
```{r}
gwps <- bind_rows(summary_backgroundstats_selected, UPL.Calcs) %>%
  filter(!key %in% upls) %>%
  left_join(mcl) %>%
  mutate(BTV = ifelse(!Chemical %in% upls, UTL,
                      Intrawell.UPL.Untransformed),
         BTV.Type = ifelse(!Chemical %in% upls, "Interwell UTL",
                      "Intrawell UPL"),
         BTV.Calc = ifelse(!Chemical %in% upls, UTL.Method,
                      Intrawell.UPL.Method),
         Location = ifelse(is.na(Location), "Upgradient wells", Location),
         GWPS = pmax(BTV, MCL.RSL),
         GWPS.Source = ifelse(BTV == MCL.RSL, "BTV = MCL/RSL",
                              ifelse(BTV > MCL.RSL, "BTV",
                                     "MCL/RSL"))) %>%
  select(Location, Chemical, BTV, BTV.Type, MCL.RSL, GWPS, GWPS.Source, BTV.Calc) %>%
    left_join(data_stats %>%  select(Chemical, report_result_unit) %>%  distinct()) %>%
  select(1:2, report_result_unit, 3:8)
write.csv(gwps, "output files/8_GWPS Summary.csv", row.names = F)

```

##6b - Define GWPS and Compare recent results, Define SSI and SSL LIst
```{r}
event_data <- data_stats %>% 
  filter(sample_date > Data.Screen.End.Date,
         !Location %in% c("Pooled Background", background.wells)) %>%
  filter(Chemical %in% upls) %>% 
  left_join(gwps %>% 
              filter(BTV.Type == "Intrawell UPL"))
event_data2 <- data_stats %>% 
  filter(sample_date > Data.Screen.End.Date,
         !Location %in% c("Pooled Background", background.wells)) %>%
  filter(!Chemical %in% upls) %>% 
  left_join(gwps %>% select(-Location) %>% 
              filter(BTV.Type == "Interwell UTL"))
  
event_data <- bind_rows(event_data, event_data2) %>% 
  mutate(SSI = ifelse(StatResult_RL > BTV, "Yes", "No"),
         GWPS.Exceedance = ifelse(StatResult_RL > GWPS, "Yes", "No")) %>% 
  distinct()
SSL.Eval.Groups <- event_data %>%  filter(GWPS.Exceedance == "Yes") %>% pull(key)

#Potential SSLs - Eval with LCL
print(SSL.Eval.Groups)
```


## 6c_Assessment Monitoring_LCL Calculations for Exceedances 
Parametric or non-parametric LCL calculations.
Need to update how we are doing these
if overall dataset is stable
```{r}

summary_CI <- NULL
CI.dataset <- NULL
#Determine appropriate LCL calc method considering data trends and data distributions
lcl.method <- mk_summary_all %>% 
  filter(key %in% SSL.Eval.Groups) %>% 
  select(key, Trend_Aziz.2003, Trend8_Aziz.2003) %>% 
  mutate(LCL.Calc = case_when(
    !Trend_Aziz.2003 %in% c("Decreasing", "Increasing") &
      !Trend8_Aziz.2003 %in% c("Decreasing", "Increasing") ~ "LCL calculation on all data",
    Trend_Aziz.2003 %in% c("Decreasing", "Increasing") & 
      !Trend8_Aziz.2003 %in% c("Decreasing", "Increasing") ~ "Overall data trend, LCL calculation on recent (8) data",
    !Trend_Aziz.2003 %in% c("Decreasing", "Increasing") & 
      Trend8_Aziz.2003 %in% c("Decreasing", "Increasing") ~ "Recent data trend, LCL calculation about the recent (8) trend line",
    Trend_Aziz.2003 %in% c("Decreasing", "Increasing") & 
      Trend8_Aziz.2003 %in% c("Decreasing", "Increasing") ~ "Overall and recent data trend, LCL calculation about the recent (8) trend line"
  ))

#Calc LCLs
for(s in SSL.Eval.Groups){

  CI.dist <- data_analysis %>% filter(key == s)
  dist <- CI.dist$Selected.Distribution[1]
  method <- lcl.method %>%  filter(key == s) %>% pull(LCL.Calc)
  overall.trend <- CI.dist$Trend_Aziz.2003[1]
  recent.trend <- CI.dist$Trend8_Aziz.2003[1]
  sub.dist <- "NA"
  #Subset data as needed and re-test for subset data distributions
  if(method %in% c("Overall and recent data trend, LCL calculation about the recent (8) trend line",
                   "Recent data trend, LCL calculation about the recent (8) trend line",
                   "Overall data trend, LCL calculation on recent (8) data")){
    
    CI.dist <- CI.dist %>% arrange(desc(sample_date)) %>% slice(1:8) 
    
    #Check distribution of subset dataframe
    # Perform Shapiro-Wilk test on recent data
    shapiro_result <- shapiro.test(CI.dist$StatResult_RL)

    CI.dist$shapiro_pvalue <- shapiro_result$p.value
    CI.dist <- CI.dist %>% 
      mutate(Subset.Distribution = ifelse(shapiro_pvalue > 0.05, "Normal", "Not Normal"))
    sub.dist <- unique(CI.dist$Subset.Distribution)
    
  }
    #Calc LCLs around trend lines where needed
    if(method %in% c("Overall and recent data trend, LCL calculation about the recent (8) trend line",
                      "Recent data trend, LCL calculation about the recent (8) trend line")){
      #Regression line
      if(sub.dist == "Normal"){
        
    # Trend-based LCL using linear regression
    trend_data <- CI.dist %>% arrange(sample_date)
    trend_model <- lm(StatResult_RL ~ as.numeric(sample_date), data = trend_data)
    preds <- predict(trend_model, interval = "confidence", level = 0.95)
    LCL <- tail(preds[,"lwr"], 1)
    UCL <- tail(preds[,"upr"], 1)
    sample_mean <- mean(trend_data$StatResult_RL)
    sample_sd <- sd(trend_data$StatResult_RL)
    calc.method <- "Regression-based LCL with confidence limits (Parametric Test for Trending Data)"
    result <- cbind(s, sample_mean, NA, sample_sd, NA, NA, 0.95, LCL, UCL, calc.method, method, sub.dist, overall.trend, recent.trend)
    
  #Theil-sen slope line  
  } else {
      
    # Nonparametric trend: Theil-Sen regression with prediction interval
      trend_data <- CI.dist %>% mutate(sample_date = as.numeric(sample_date)) %>% arrange(sample_date)
      trend_model <- mblm(StatResult_RL ~ sample_date, data = trend_data, repeated = FALSE)
      preds <- predict(trend_model, interval = "confidence", level = 0.95)
      LCL <- tail(preds[,"lwr"], 1)
      UCL <- tail(preds[,"upr"], 1)
      sample_median <- median(trend_data$StatResult_RL)
      sample_sd <- sd(trend_data$StatResult_RL)
      sample_mean <- mean(trend_data$StatResult_RL)
      calc.method <- "Theil-Sen-Based LCL with confidence limits (Nonparametric Test for Trending Data)"
      result <- cbind(s, sample_mean, sample_median, sample_sd, NA, NA, 0.95, LCL, UCL,  calc.method, method, sub.dist, overall.trend, recent.trend)
      
  }
      #Standard LCL calcs about mean or median, non-trending data
    } else if(method %in% c("LCL calculation on all data", 
                            "Overall data trend, LCL calculation on recent (8) data")){
      
      #Normal mean
      if((dist == "Normal" & method == "LCL calculation on all data") | 
         (sub.dist == "Normal" & method == "Overall data trend, LCL calculation on recent (8) data")){
        
      CI.data <- CI.dist %>% select(key, sample_date, StatResult_RL) %>% arrange(StatResult_RL) %>% mutate(rank = row_number())
      write.csv(CI.data, sprintf("output files/6b_LCL check/%s %s.csv", gsub(", ", " ", s), dist))

      data.to.test <- CI.data$StatResult_RL
      sample_mean <- mean(data.to.test)
      sample_sd <- sd(data.to.test)
      n <- length(data.to.test)
      t_value <- qt(0.975, df = n - 1)
      margin_error <- t_value * sample_sd / sqrt(n)
      LCL <- sample_mean - margin_error
      UCL <- sample_mean + margin_error
      calc.method <- "Calculation of the Confidence Interval Around the Normal Mean (Parametric)"
      distribution <- ifelse(method == "Overall data trend, LCL calculation on recent (8) data", sub.dist, dist)
      result <- cbind(s, sample_mean, NA, sample_sd, NA, NA, 0.95, LCL, UCL, calc.method, method, distribution, overall.trend, recent.trend)

      #Bootstrap about median, nonparametric
    } else {
      
      CI.data <- data_copc_out_adj %>% filter(key == s) %>% select(key, sample_date, StatResult_RL) %>% arrange(StatResult_RL) %>% mutate(rank = row_number())
      write.csv(CI.data, sprintf("output files/6b_LCL check/%s %s.csv", gsub(", ", " ", s), dist))

      set.seed(123)
      boot_result <- boot(CI.data$StatResult_RL, statistic = function(x, i) median(x[i]), R = 10000)
      LCL <- quantile(boot_result$t, 0.025)
      UCL <- quantile(boot_result$t, 0.975)
      sample_median <- median(CI.data$StatResult_RL)
      sample_mean <- mean(CI.data$StatResult_RL)
      sample_sd <- sd(CI.data$StatResult_RL)
      distribution <- ifelse(method == "Recent data trend, LCL calculation about the recent (8) trend line", sub_dist, dist)
      calc.method <- "Bootstrap Calculation of the Confidence Interval Around the Median (Non-Parametric)"
      result <- cbind(s, sample_mean, sample_median, sample_sd, 10000, boot_result$t[1], 0.95, LCL, UCL, calc.method, method, distribution, overall.trend, recent.trend)
    }
  }

  CI.dataset <- bind_rows(CI.dataset, CI.dist)
  summary_CI <- rbind(result, summary_CI)

  # Create histogram with confidence limits
  jpeg(sprintf("output files/6b_LCL check/%s %s.jpeg", gsub(", ", " ", s), dist), 
       width = 5, height = 5, units = "in", res = 300)
  hist(CI.dist$StatResult_RL, col = "lightblue", main = "Histogram with CI", xlab = "Data")
  abline(v = as.numeric(LCL), col = "blue", lty = 2)
  abline(v = as.numeric(UCL), col = "red", lty = 2)
  dev.off()
} 

colnames(summary_CI) <- c("key", "mean", "median", "standard deviation", "bootstrap iterations", 
                          "bootstrap median", "confidence level for test", "LCL", "UCL", "CI Calculation Method", 
                          "Data handling consideration", "Tested Data Distribution", "Overall Trend", "recent (8) Trend")
summary_CI <- as.data.frame(summary_CI) %>% 
  mutate(key2 = key) %>% 
  separate(key2, into = c("Location","Chemical"), sep = "_") %>% distinct()
write.csv(summary_CI, "output files/6b_LCL check/10b_CI summary for potential SSLs.csv")

Assessment.Monitoring.SSLs <- left_join(event_data, summary_CI, by = c("key", "Chemical", "Location")) %>% 
  mutate(GWPS_Exceedance = ifelse(as.numeric(StatResult_RL) > GWPS, "Yes", "No"),
         SSL.prelim = ifelse(StatResult_RL > GWPS, "Yes", "No")) %>% 
  filter(SSL.prelim == "Yes") %>% 
  mutate(LCL = ifelse(GWPS_Exceedance == "Yes", LCL, ""),
         SSL.Confirmed = ifelse(GWPS_Exceedance == "Yes" & as.numeric(LCL) > as.numeric(GWPS), "Yes", 
                                "No")) %>% 
  select(-c("standard deviation", 'confidence level for test'))
write.csv(Assessment.Monitoring.SSLs, "output files/7c_Confirmed SSLs for event_Assessment Monitoring.csv")

Assessment.Monitoring.SSLs_all <- left_join(event_data, summary_CI, by = c("key", "Chemical", "Location")) %>% 
  mutate(GWPS_Exceedance = ifelse(as.numeric(StatResult_RL) > GWPS, "Yes", "No"),
         SSL.prelim = ifelse(StatResult_RL > GWPS, "Yes", "No")) %>% 
  mutate(LCL = ifelse(GWPS_Exceedance == "Yes", LCL, ""),
         SSL.Confirmed = ifelse(GWPS_Exceedance == "Yes" & as.numeric(LCL) > as.numeric(GWPS), "Yes", 
                                "No")) %>% 
  select(-c("standard deviation", 'confidence level for test'))

```

##GWPS COMPARISON - COMBINED UTL AND UPL 
```{r}

gwps_comparison <- event_data %>% 
  left_join(summary_CI %>%  select(Location, Chemical, LCL)) %>%
  mutate(SSL = ifelse(GWPS.Exceedance == "No", "No",
                      ifelse(LCL > GWPS, "Yes", "No")),
         Sample.Result = paste(StatResult_RL, final_qualifiers, sep = " ")) %>%
  select(c(Location, Chemical, report_result_unit, sample_date, Sample.Result, BTV, BTV.Type, GWPS, 
           GWPS.Exceedance, LCL, SSL)) #If no GWPS Exceedances, you won't have a LCL column, so just mutate a new one
write.csv(gwps_comparison, "output files/8_GWPS Comparison.csv", row.names = F)

```


#Report Tables
## Table 1. SSLs (Confirmed)- Assessment Monitoring Only
###If no SSLs are confirmed, then table is blank and will get subscript out of bounds error
```{r}

##SSLs
data_SSLs_all <- data_analysis %>%
  left_join(Assessment.Monitoring.SSLs)
 
data_SSLs <- Assessment.Monitoring.SSLs %>%
  left_join(data_analysis) %>%  
  filter(SSL.Confirmed == "Yes") %>% 
  mutate(LCL = formatC(as.numeric(LCL), digits = 3),
         GWPS = formatC(as.numeric(GWPS), digits = 3),
         Seasonality.identified = ifelse(Seasonality.identified == "No", "No Trend",
                                                       "Seasonal Trend"),
         Report_Result_RL = paste(StatResult_RL, final_qualifiers, sep = " "),
         newly.id = ifelse(SSL.Confirmed == "No", "NA", ifelse(Location == "CCR-AP-5" & Chemical == "Molybdenum, Total", "No", 
                                                               "Check past event's report"))) %>% 
  select(c(Location, Chemical, Report_Result_RL, newly.id,
           Trend_Aziz.2003, Trend8_Aziz.2003)) %>%
  arrange(Location) %>% 
  arrange(Chemical) %>% 
  filter(!Chemical %in% upls)

data_SSLs[data_SSLs == ""] <- "NA"

colnames(data_SSLs) <- c("Location", "Constituent",
                         "Event Concentration (mg/L)",
                         "Newly Identified SSL",
                         "Trend (All Data)", "Trend (Recent 8 data points)"
                         # "Trend (All Data)",
                         # "Trend (Recent Data)"
                         )

write.csv(data_SSLs, "output files/report tables/Table 1.csv")

t1 <- data_SSLs %>%
  kbl(caption = "Table 1. Statistically Significant Level Summary - Appendix IV Constituents",
      align = "c", bold = TRUE) %>%
  kable_classic_2(full_width = FALSE, html_font = "Calibri",
                  "striped", font_size = 10,
                  position = "left") %>%
  add_footnote("Notes: mg/L = milligrams per liter",
               notation = "none") %>%
  row_spec(0, bold = TRUE, color = "black", background = "grey90",align = "center") %>%
  column_spec(c(1,2,3,4), width_min = "100px") %>%   
  column_spec(c(1), border_left = TRUE) %>% 
  column_spec(c(1,2,3,4,5), border_right = TRUE)
print(t1)
kableExtra::save_kable(t1, "output files/report tables/Table 1. SSLs.html")

```

## Table 2. Trend Summary
```{r}
##Summary of Increasing Trends
data_trends <- mk_summary_all %>% 
  filter(Location != "Pooled Background") %>% #Remove if UTLs are not updated
  mutate(rate_per_year = as.numeric(rate_per_year),
         rate_per_year8 = as.numeric(rate_per_year8),
         units = ifelse(Chemical == "Radium-226 & 228", "pCi/L", "mg/L")) %>% 
         select(c(Location, Chemical, units,
           Trend_Aziz.2003, Trend8_Aziz.2003, 
           nResults, nDetects,
           r_max,
           rate_per_year, 
           nResults8, nDetects8, 
           r_max8, 
           rate_per_year8          )) %>% 
  arrange(Location) %>% 
  arrange(Chemical) %>% 
  mutate(across(c(5:13), \(x) formatC(x, 3))) %>% 
  mutate(Trend_Aziz.2003 = gsub("\\.", "", Trend_Aziz.2003),
         Trend8_Aziz.2003 = gsub("\\.", "", Trend8_Aziz.2003)) %>% 
  mutate(order = ifelse(Trend_Aziz.2003 == "Increasing", 1, 
                        ifelse(Trend8_Aziz.2003 == "                                        Increasing", 2, 
                               3))) %>% 
  arrange(Location) %>% 
  arrange(Chemical) %>% 
  arrange(order) %>% select(-order)
data_trends$Trend8_Aziz.2003 <- trimws(data_trends$Trend8_Aziz.2003, "left") 


colnames(data_trends) <- c("Location", "Chemical", "Units",
                           "Trend (All Data)", "Trend (Recent Data)",
                           "Results, n", "Detected Results, n",
                           "Max Concentration", 
                           "Sen Slope (units per year)",
                           "*Results, n", "*Detected Results, n", "*Max Concentration", 
                           "*Sen Slope (units per year)"
                           )
sum <- data_trends %>% 
  filter(!Location %in% background.wells) %>% 
  group_by(Chemical, Location, `Trend (All Data)`) %>% 
  summarise(n = n())
write.csv(sum, "output files/trend sum.csv"
)
write.csv(data_trends, "output files/report tables/Table 1. Trend Summary.csv")

t4 <- data_trends %>% 
kbl(caption = "Table 1. Trend Summary",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri",
                  bootstrap_options = "striped", font_size = 10,
                  position = "left") %>% 
  add_footnote( c(
    "Abbreviations: CF = confidence facotr; CV = coefficient of variation; mg/L = milligrams per liter; pCi/L = picocuries per liter.",
    "Notes: *Recent data defined as the 8 most recent data points. MK = Mann Kendall Trend Test. Secular Trend Classification based on Aziz (2003) guidance and MK Results. Sen slope only calculated for increasing or decreasing trends as indicated by Mann-Kendall trend test results.", "Additional information about trend analysis provided in Attachment A."
   ),
   notation = "none") %>%
  add_header_above(c(" " = 3, "Identified Trends" = 2, "Trend Analysis on All Available Data" = 4, "Trend Analysis on Recent Data" = 4), bold = TRUE) %>%
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
  column_spec(c(1,3), width_min = "60px")  %>%  # Adjust width of the first column
  column_spec(c(2), width_min = "100px")  %>%  # Adjust width of the first column
  # column_spec(c(4,5),width_min = "150" width_min = "150") %>%
  column_spec(c(3,5,8,9,12,13), border_right = TRUE) %>%
  column_spec(c(1), border_left = TRUE) %>% # Add vertical line after the second column
  column_spec(4, color  = ifelse(data_trends$`Trend (All Data)` == "Increasing", "orange",
       ifelse(data_trends$`Trend (All Data)` == "Decreasing",
       "darkblue", "black")),
       width_min = "100px") %>%
  column_spec(5, color  = ifelse(data_trends$`Trend (Recent Data)` == "Increasing", "orange",
       ifelse(data_trends$`Trend (Recent Data)` == "Decreasing",
       "darkblue","black")),
       width_min = "100px") %>%
  row_spec(c(1:nrow(data_trends)),extra_css = "border-bottom: 0.5px solid")


print(t4)
kableExtra::save_kable(t4, "output files/report tables/Table 1. Increasing Trend Summary.html")

```

# Appx
## Tables
### Stats summary
```{r}

stat_sum_final[stat_sum_final == ""] <- "NA"
rownames(stat_sum_final) <- NULL

units <- data_analysis %>%  select(Chemical, report_result_unit) %>% distinct()

stat_sum_final2 <- stat_sum_final %>% 
  # filter(Location != "Pooled Background") %>%  #Remove if not updating UTLs
  left_join(units) %>% 
    mutate(`Percent of non-detects` = format(`Percent of non-detects`, digits = 1),
         `variance` = format(as.numeric(`variance`),scientific = TRUE, digits = 2),
         `sd` = format(as.numeric(`sd`),scientific = TRUE, digits = 2),
         rl_range = paste(min_RL, max_RL, sep = " - "),
         rl_range = ifelse(rl_range == "NA - NA", "NA", rl_range),
         date_range = paste(as.Date(min_date, format = "%m/%d/%Y"), as.Date(max_date, format = "%m/%d/%Y"), sep = " to ")) %>% 
  select(Location, Chemical, report_result_unit, n, n_nd, `Percent of non-detects`, 
         max, min, mean, median, sd, variance, rl_range, date_range) %>% 
  mutate_at(vars(7:12), as.numeric) %>% 
  mutate(across(c(7:12), \(x) formatC(x, 3))) %>% 
  distinct() %>% 
  arrange(Location) %>% 
  arrange(Chemical) 

colnames(stat_sum_final2) <- c("Location", "Constituent",  "Units",
                              "n", "n, non-detects", "percent of non-detects",
                               "max", "min", "mean", "median",
                              "standard deviation", "variance", 
                              "reporting limit range", "date range")


  

 a1 <-
 stat_sum_final2 %>%
  kable(caption = "Table A-1. Descriptive Statistics",
      align = "c", repeat_header = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left",  "striped") %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%  
   column_spec(c(1,2,3,4,5,6,7,8,9,10,11,12,13,14), border_right = TRUE) %>%  
      column_spec(1, border_left = TRUE) %>%  
footnote(
    general = c("Units: mg/L = milligrams per liter, pCi/L = picocuries per liter")
) %>% 
    column_spec(c(3), width_min = "60px")  %>% 
column_spec(c(1,2), width_min = "100px") %>%
   column_spec(c(13), width_min = "80px")  %>% 
         column_spec(c(14), width_min = "125px")  %>% 
         column_spec(c(4,5,6,7,8,9,10,11,8), width_min = "50")  %>% 
    row_spec(c(1:nrow(stat_sum_final2)),extra_css = "border-bottom: 0.25px solid")


print(a1)
kableExtra::save_kable(a1, "output files/Appx/Table 1. Descriptive Statistics.html")
```
### Initial Data Distribution Check
```{r}
summary_SW[summary_SW == ""] <- "NA"
rownames(summary_SW) <- NULL

  summary_SW2 <- summary_SW %>% 
  # filter(Location != "Pooled Background") %>%  #UTLS NOT UPDATEd
  select(-c(Analysis, key)) %>% 
  mutate(`WStatistic.SW` = formatC(as.numeric(`WStatistic.SW`), digits = 4),
         `PValue.SW` = formatC(as.numeric(`PValue.SW`), digits = 4),
         Distribution.99 = gsub("\\(99% Confidence)", "", Distribution.99),
         `WStatistic.SWln` = formatC(as.numeric(`WStatistic.SWln`), digits = 4),
         `PValue.SWln` = formatC(as.numeric(`PValue.SWln`), digits = 4),) %>% 
  select(c(Location, Chemical, n, n_nd, WStatistic.SW, PValue.SW, Distribution.99,
           WStatistic.SWln, PValue.SWln, Distribution.99ln, Selected.Distribution)) %>% 
  distinct() %>% 
    arrange(Location) %>% 
  arrange(Chemical)
  
  colnames(summary_SW2) <- c("Location", "Constituent", 
                            "n", "n, non-detects",
                          "W statistic", "p-value", 
                          "Data Normality (significance level = 0.01)",
                          "W statistic", "p-value", 
                          "Data Lognormality (significance level = 0.01)",
                          "Distribution"
                          )
  
a2 <-summary_SW2 %>%
  kable(caption = "Table A-2. Results of Shapiro-Wilk Test for Normality",
      align = "c") %>%
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left",  "striped") %>%
    add_header_above(c(" " = 4,
                       "Shapiro-Wilk Test for Normality (R programming, package = stats, version 4.3.3, function = shapiro.test, non-detects substituted by 0.5*reporting limit)" =3,
                       "Shapiro-Wilk Test for Lognormality (R programming, package = stats, version 4.3.3, function = shapiro.test, non-detects substituted by 0.5*reporting limit)" =3, " " = 1), bold = TRUE, color = "grey30") %>%
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
   column_spec(2, width_min = "100px")  %>%
   column_spec(1, width_min = "100px")  %>%
   column_spec(c(3,4,5,6,8), width = "60px")  %>%
   column_spec(c(7,10), width = "175px")  %>%
   column_spec(c(1,2,3,4,7,10,11), border_right = TRUE) %>%
   column_spec(1, border_left = TRUE) %>%
    row_spec(c(1:nrow(summary_SW2)),extra_css = "border-bottom: 0.25px solid")

print(a2)
kableExtra::save_kable(a2, "output files/Appx/Table 2. SW Normality.html")
```
### Outlier Test
```{r}

summary_RD[summary_RD == ""] <- "NA"
rownames(summary_RD) <- NULL

summary_RD2 <- summary_RD %>%
  separate(key, into = c("Location", "Chemical"), sep = "_") %>% 
  # filter(Location != "Pooled Background") %>%  #Remove if not updating UTLs
  select(c(Location, Chemical, n, n_nd, `Outlier Test`, Statistic.Out,P.value.Out, 
           Critical.Value.Out, `n of potential outliers (Rosner)`)) %>% 
  mutate(Statistic.Out = gsub("All results are non-detects.", "All results are non-detect", Statistic.Out),
         `Statistic.Out` = Statistic.Out,
         `P.value.Out` = formatC(as.numeric(`P.value.Out`), digits = 4),
         Critical.Value.Out = ifelse(Critical.Value.Out == "NA", "NA", 
                                           `Critical.Value.Out`),
         Statistical.Outlier.Dixon = ifelse(as.numeric(P.value.Out) < 0.05, "Yes", "No"),
         `n of potential outliers (Rosner)` = as.numeric(`n of potential outliers (Rosner)`),
         `Outlier Removed` = ifelse(Statistical.Outlier.Dixon == "Yes" , "No", "NA"),
         `Outlier Removed.2` = ifelse(`n of potential outliers (Rosner)` == 3, "No",
                                           "NA"),
         `Outlier Removed` = ifelse(is.na(`Outlier Removed`), `Outlier Removed.2`,
                                    `Outlier Removed`)) %>% select(-`Outlier Removed.2`) %>% 
  arrange(Location) %>% 
  arrange(Chemical) 
names(summary_RD2)
colnames(summary_RD2) <- c("Location", "Constituent", 
                          "n", "n, non-detects", "Outlier Test",
                          "statistic",  "p-value (Dixon)",           
                          "critical value (Rosner)", "n of statistical outliers (significance level = 0.05, Rosner)",
                          "statistical outlier (significance level = 0.05, Dixon)", "outlier removed")
 a3 <-
  summary_RD2 %>%
  kbl(caption = "Table A-3. Results of Rosner/Dixon Test for Outliers",
      align = "c") %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
   add_header_above(c(" " = 2,
                      "Rosner or Dixon Test for Outliers (R programming, package = outliers, version 0.15, function = dixon.test or rosnerTest, non-detects substituted by 0.5*reporting limit)" = 9), bold = TRUE, color = "grey30") %>%
  row_spec(0, bold = TRUE, color = "black", align = "center") %>% 
   row_spec(0, bold = TRUE, color = "black", align = "center") %>%  
 column_spec(c(1,2,3,4,5,6,7,8,9,10,11), border_right = TRUE) %>%  
      column_spec(1, border_left = TRUE, width_min = "100px") %>%  
      column_spec(c(2), width_min = "100px")  %>% 
           column_spec(c(8,6), width_min = "150px")  %>%
        column_spec(c(10,9), width_min = "60px")  %>%

   # column_spec(8, color  = ifelse(summary_RD2$`Statistical Outlier` == "No", "black",
   #                                      ifelse(summary_RD2$`Statistical Outlier` == "Yes",
                                                         # "darkblue", "grey"))) %>%  
  row_spec(c(1:nrow(summary_RD2)),extra_css = "border-bottom: 0.25px solid")

print(a3)
kableExtra::save_kable(a3, "output files/Appx/Table 3. RD Outliers.html")
```
### Secular Trends
```{r}

mk_summary_all[mk_summary_all == ""] <- "NA"
rownames(mk_summary_all) <- NULL

date_range <- data_analysis %>% 
  group_by(Chemical, Location) %>%
  arrange(desc(sample_date)) %>% 
  slice(1:8) %>% 
  select(Chemical, Location, sample_date) %>% 
  group_by(Chemical, Location) %>% 
  summarise(min_date = min(sample_date),
            max_date = max(sample_date))
  
mk_summary_all2 <- mk_summary_all %>% 
  select(c(Location, Chemical, 
           Trend_Aziz.2003, Trend8_Aziz.2003,
           nResults, nDetects, nValues, COV, 
           mk_t, mk_p, mk_conf.factor, mk_Score, 
           senslope,INTERCEPT,rate_per_year,
           nResults8, nDetects8, nValues8, COV8, 
           mk_t8, mk_p8, mk_conf.factor8, mk_Score8, 
           senslope8, intercept8, rate_per_year8
           )) %>% 
  mutate_if(is.numeric, format, digits=4,nsmall = 0) %>% 
  arrange(Location) %>% 
  arrange(Chemical) %>% 
  select(-nValues, -nValues8) %>% 
    mutate_at(vars(c(14,10,19,23,9)), ~ gsub("Majority of data (>50%) non-detect", "NA",  ., fixed = TRUE)) %>% 
    mutate_at(vars(c(14,10,19,23,9)), ~ gsub("Only one detected result", "NA", .)) %>% 
    mutate_at(vars(c(10,14,19,23,9)), ~ gsub("No detected results", "NA", .)) %>% 
  left_join(date_range) %>% 
  mutate(date_range = paste(min_date, max_date, sep = " to "),
         date_range = ifelse(date_range == "NA to NA", "NA", date_range)) %>% 
  select(-min_date, -max_date) %>% 
  select(1:17, date_range, 18:25)  %>% 
  mutate(across(c(12:14,23:25), ~ as.numeric(.))) %>% 
   mutate(across(c(12:14,23:25), ~ formatC(.,digits = 2)))

# print(colnames(mk_summary_all))         
colnames(mk_summary_all2) <- c("Location", "Constituent", 
                          "Trends, All Data","Trends, Recent Data",
                          "n", "n, detected results",                        
                          "Coefficient of Variance", "Kendall's Tau", "p-value",
                          "Confidence Factor", "Kendall Score (S)","Sen Slope", 
                          "Intercept (for slope in units of change per year)", 
                          "Sen Slope (units of change per year)", 
                          "n", "n, detected results","Coefficient of Variance",
                          "recent data date range",                      
                          "Kendall's Tau", "p-value",
                          "Confidence Factor", "Kendall Score (S)",
                          "Sen Slope", "Intercept (for slope in units of change per year)",
                          "Sen Slope (units of change per year)"
                          )
# print(unique(mk_summary_all2$ss_p))

 a5 <-
  mk_summary_all2 %>%
  kbl(caption = "Table A-4. Results of Mann Kendall and Thiel Sen Trend Tests",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  add_header_above(c(" " = 2, 
                     "Mann Kendall Trends" = 2,
                     "Mann-Kendall Test\n(R programming, package = Kendall, version = 2.2.1, function = MannKendall, non-detects substituted by 0.5*reporting limit)" = 7,
                     "Thiel-Sen Test\n(R programming, package = zyp, version = 0.11-1, function = zyp.sen, non-detects substituted by 0.5*reporting limit)" = 3,
                     "Mann-Kendall Test\n(R programming, package = Kendall, version = 2.2.1, function = MannKendall, non-detects substituted by 0.5*reporting limit)" = 8,
                     "Thiel-Sen Test\n(R programming, package = zyp, version = 0.11-1, function = zyp.sen, non-detects substituted by 0.5*reporting limit)" = 3), bold = TRUE, 
                   color = c("black", "black", "black", "black", "grey", "grey")) %>%
    
  add_header_above(c(" " = 4,
                       "Secular Trend Evaluation for All Data" = 10,
                       "Secular Trend Evaluation for Recent Data (subset of 8 most recent data points)" = 11), bold = TRUE, 
                     color = c("black", "black", "grey"), font_size = 8) %>%
    
  row_spec(0, bold = TRUE, 
           color = c("black", "black",  "black", "black",  
                            "black",  "black", "black",  
                            "black",  "black", "black",  
                            "black",  "black", "black",  "black",
                            "grey","grey","grey",
                            "grey","grey","grey",
                            "grey","grey","grey","grey"),
           align = "center") %>% 
  column_spec(c(1,2), width_min = "100px") %>% 
  column_spec(c(18), width_min = "120px") %>% 
  column_spec(c(3,4), width_min = "110px") %>% 
  column_spec(c(1:2,6:14), color = "black", bold = TRUE) %>% 
  column_spec(c(2,4,11,14,22,25), border_right = TRUE) %>%  
  column_spec(1, border_left = TRUE)  %>% 
  column_spec(3, color  = ifelse(mk_summary_all2$`Trends, All Data`  == "Increasing", "orange",
                                        ifelse(mk_summary_all2$`Trends, All Data` == "Decreasing",
   "darkblue",
    ifelse(mk_summary_all2$`Trends, All Data` == "Probably Decreasing", "skyblue",
            ifelse(mk_summary_all2$`Trends, All Data` == "Probably Increasing", "gold",
                    ifelse(mk_summary_all2$`Trends, All Data` == "Stable", "black",
           "grey")))))) %>%
      column_spec(4, color  = ifelse(mk_summary_all2$`Trends, Recent Data`  == "Increasing", "orange",
                                        ifelse(mk_summary_all2$`Trends, Recent Data` == "Decreasing",
   "darkblue",
    ifelse(mk_summary_all2$`Trends, Recent Data` == "Probably Decreasing", "skyblue",
            ifelse(mk_summary_all2$`Trends, Recent Data` == "Probably Increasing", "gold",
                    ifelse(mk_summary_all2$`Trends, Recent Data` == "Stable", "black",
           "grey")))))) %>%
  row_spec(c(1:nrow(mk_summary_all2)),extra_css = "border-bottom: 0.25px solid") %>% 
   footnote(general = c("Mann Kendall test run on seasonally adjusted data if a seasonal trend was identified.
                        Mann Kendall Trends are classified based on Aziz (2003) guidance. Sen slope only calculated for increasing or decreasing trends as indicated by Mann-Kendall trend test results."))

 
 print(a5)

kableExtra::save_kable(a5, "output files/Appx/Table 4. MK-TS Secular Trends.html")



```
### UTL Calcs - Assesment Monitoring
```{r}

summary_backgroundstats_selected[summary_backgroundstats_selected == ""] <- "NA"
rownames(summary_backgroundstats_selected) <- NULL

BACKGROUND_DATES <- data_back %>% 
 group_by(category, Chemical) %>% 
  summarise(`Min Sample Date (Interwell Background)` = min(sample_date),
            `Max Sample Date (Interwell Background)` = max(sample_date))
  
UTLtbl <- summary_backgroundstats_selected %>% 
  ungroup() %>% 
  select(-c(key, Site)) %>% 
  left_join(data_stats %>%  select(Chemical, report_result_unit) %>%  distinct()) %>% 
  left_join(background_summary) %>%
  left_join(BACKGROUND_DATES) %>% 
  arrange(Chemical) %>% 
  left_join(Assessment.Monitoring.SSLs_all %>%
              select(c(Chemical, MCL.RSL, GWPS, GWPS.Source)), by = "Chemical") %>%
  distinct() %>% 
  select(Chemical, report_result_unit, 
         n_Background, n_nd_Background, 
         `Max Reporting Limit (Interwell Background)`, `Max Detected Result (Interwell Background)`,
         mean_Background, `Median (Interwell Background)`,
         `Min Sample Date (Interwell Background)` , `Max Sample Date (Interwell Background)`,
         sd_Background, COV, Background.Trend_Aziz.2003,  Distribution, Transformation,
         UTL, `UTL Detection Status`, MCL.RSL, GWPS, GWPS.Source, UTL.Method, UTL.Method.Detail, `Minimum Coverage (%)`,
         # `One-sided normal tolerance factor (K) at 95% coverage and 95% probability` unfreeze this line if we ever use parametric methods to calc UTLs at this unit, but unlikely
         ) %>% ungroup() %>% 
  mutate(across(c(5:8, 11:23), \(x) formatC(x, 3))) 

colnames(UTLtbl) <- c("Constituent", "Units",
                          "n", "n, non-detects",
                      "max reporting limit", "max detected value",
                          "mean",
                      "median", "min sample date", "max sample date",
                          "standard deviation", 
                          "coefficient of variation",
                          "Mann Kendall trend", 
                          "data distribution (Shapiro-Francia) [b]",
                          "normalizing data transformation (if any)",
                          "UTL", "UTL Result Detection Status [c]",
                          "MCL/RSL", "GWPS", "GWPS Source",
                          "UTL calculation method",
                          "UTL calculation details",
                          "Minimum Coverage (%)"
                      # "One-Sided tolerance factor (K)"
                          ) 




 a7 <-
  UTLtbl %>%
  kbl(caption = "Table A-5. Upper Tolerance Limits (UTLs) & Updated Groundwater Protection Standards (GWPS), Assessment Monitoring",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  add_header_above(c(" " = 2,
                    "Interwell Background Data Characterization [a]" = 13,
                    "Groundwater Protection Standard (GWPS) Determination" = 5,
                    "UTL Calculation Details" = 3
                    # "Parametric UTL Statistics" = 1,
                    ), 
                   bold = TRUE, color = "grey30") %>% 
  footnote(
    general = c("[a] Interwell background datasets are analyte specific and include data collected from background wells (CCR-AP-7 and WAP-1). Interwell background datasets were re-tested for outliers, secular trends, and data normality. No outliers were removed. Presented values are in original (untransformed) units.",
                "[b] Parametric tolerance limit calculations were performed on normally distributed background data. If background data were not normally distributed, non-parametric tolerance limit calculations were performed.",
                "[c] In some cases, the maximum value selected as the UTL is a non-detect result with an elevated reporting limit.",
                "Units = mg/L, milligrams per liter. pCi/L = picocuries per liter."
    )
  ) %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
    column_spec(c(1), width_min = "80px") %>%  # Adjust width of the first column
    column_spec(c(9,10,13,16), width_min = "70px") %>%
    column_spec(c(22,15, 21), width_min = "115px")  %>%   
    column_spec(c(2,14, 20,23),  border_right = T) %>% 
       column_spec(c(1),  border_left = T) %>% 
     row_spec(c(1:nrow(UTLtbl)),extra_css = "border-bottom: 0.25px solid")
print(a7)
kableExtra::save_kable(a7, "output files/Appx/Table 5. UTL Calculations.html")


```
### Intrawell UPLs -  Arsenic
```{r}
sum <- data_stats %>% 
  filter(sample_date < UPL.Update.Date,
         Chemical %in% upls,
         !Location %in% background.wells) %>%  
  group_by(Location, Chemical) %>% 
  summarise(max = max(StatResult_RL),
            mean = mean(StatResult_RL),
            sd = sd(StatResult_RL),
            min_date = min(sample_date),
            max_date = max(sample_date))

data_SSIs_intrawell_all <-  UPL.Calcs %>% 
  mutate(Confidence.Level_pct = ifelse(`Prediction Interval Calculation Method` == "Non-Parametric",
                                       "NA", formatC(Confidence.Level_pct, 4)),
         future.samples = 4,
         t = ifelse(`Prediction Interval Calculation Method` == "Non-Parametric",
                    "NA", formatC(t, 4)),
         t_quantile = ifelse(`Prediction Interval Calculation Method` == "Non-Parametric",
                             "NA", formatC(t_quantile, 4)),
         `Confidence.Level (%) for Non-Parametric UPL(s)` = 
           ifelse(`Prediction Interval Calculation Method` != "Non-Parametric",
                  "NA", 
                  formatC(Intrawell.Baseline.n / (Intrawell.Baseline.n + future.samples)*100,3)),
         `False Positive Rate (%) for Non-Parametric UPL(s)` = 
           ifelse(`Prediction Interval Calculation Method` != "Non-Parametric",
                  "NA", 
                  formatC(100-as.numeric(`Confidence.Level (%) for Non-Parametric UPL(s)`), 3))
         ) %>% 
  left_join(sum %>% select(Location, Chemical, min_date, max_date)) %>% 
  select(Location, Chemical, report_result_unit, selected_distribution, 
         `Prediction Interval Calculation Method`,
         min_date, max_date, 
         Intrawell.Baseline.n, n_nd_Baseline, 
         Intrawell.Baseline.max,
         Intrawell.Baseline.mean, Intrawell.Baseline.sd, 
         trend, Degrees.of.freedom, 
         future.samples, Intrawell.UPL.Method,
         Intrawell.UPL.Untransformed,  Confidence.Level_pct, t, t_quantile,
         `Confidence.Level (%) for Non-Parametric UPL(s)`,
         `False Positive Rate (%) for Non-Parametric UPL(s)`) %>% 
mutate(across(c(10:12,15,16,17,18,19,20), \(x) formatC(x, 3))) %>% 
  arrange(Location) %>% 
  arrange(Chemical)

colnames(data_SSIs_intrawell_all) <- c("Location", "Constituent", "Units", 
                             "Baseline Distribution [a]", "Prediction Interval Calculation",
                             "min baseline sample date",
                             "max baseline sample sample", 
                             "n", "n, non-detects", "max", "mean",
                             "standard deviation","Trend (Baseline Data)", 
                             "degrees of freedom", 
                             "future samples (M)", 
                             "Prediction Limit Calculation Method","UPL", 
                             "confidence level (%)", "t (percentile of student's t-test)", 
                             "t quantile", "actual confidence level (%)", "false positive rate (%)"
                             )


data_SSIs_intrawell_all[data_SSIs_intrawell_all == ""] <- "NA"
rownames(data_SSIs_intrawell_all) <- NULL

 a6 <-
  data_SSIs_intrawell_all %>%
  kbl(caption = "Table A-6. Intrawell Upper Prediction Limit (UPL) Calculations",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  add_header_above(c(" " = 3,
                    "Baseline Data Characterization [a]" = 11,
                    "Prediction Limits" = 3,
                    "Parametric UPL Calculation Statistics" = 3,
                    "Non-Parametric UPL Calculation Statistics" = 2), 
                   bold = TRUE, color = "grey30")  %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
    column_spec(c(6,7), width_min = "60px") %>%  # Adjust width of the first column
    column_spec(c(16,22), width_min = "150px") %>% 
       column_spec(1, border_left = TRUE, width_min = "75px")  %>% 
   column_spec(c(4,13), width_min= "125px") %>% 
       column_spec(c(2,5), width_min = "75px") %>% 
          column_spec(c(21,22,20,19,18), width_min = "15px") %>% 
    column_spec(c(3,14,17,20,22), border_right = T) %>% 
  row_spec(c(1:nrow(data_SSIs_intrawell_all)),extra_css = "border-bottom: 0.25px solid")

print(a6)
kableExtra::save_kable(a6, "output files/Appx/Table 6. UPL Calculations.html")
```
### CI Calcs
```{r}

summary_CI[summary_CI == ""] <- "NA"
rownames(summary_CI) <- NULL

CI_stats <- CI.dataset %>% 
  mutate(Constituent = Chemical) %>% 
  group_by(Constituent, Location) %>% 
  summarise(n = n(),
            max = max(StatResult_RL),
            min = min(StatResult_RL),
            median = median(StatResult_RL),
            mean = mean(StatResult_RL))


LCLtbl <- summary_CI %>% 
  separate(key, into = c("Location", "Chemical"), sep = "_") %>% 
  select(c(1,2,11,8,9,10,3,5,4,6,7,12,13,14,15)) %>% 
  mutate(LCL = as.numeric(LCL),
         UCL = as.numeric(UCL)) %>% 
  mutate(Constituent = Chemical) %>%  select( -median, -mean) %>% 
  left_join(stat_sum_final2 %>% 
              select(Constituent, Units)) %>% 
  left_join(CI_stats %>% ungroup() %>% select(c(Location, Constituent, n, max, min, median, mean))) %>%
  mutate(`standard deviation` = as.numeric(`standard deviation`)) %>% 
    mutate(across(c(5:7, 17:20), \(x) formatC(x, 3))) %>% 
    left_join(Assessment.Monitoring.SSLs %>%  ungroup() %>% 
              select(c(Chemical,Location, GWPS,SSL.prelim)), by = c("Chemical", "Location")) %>% distinct() %>% 
  filter(SSL.prelim == "Yes") %>% select(-SSL.prelim) %>% #LCL calcualted for other constituents  
  ungroup() %>% 
  arrange(Location) %>% 
  arrange(Constituent) %>% 
  mutate(`95% LCL > GWPS` = ifelse(as.numeric(LCL) > as.numeric(GWPS), "Yes, SSL", "No"),
         DF = n-1,
         GWPS = formatC(as.numeric(GWPS), digits = 3)) %>% 
  select(Location, Chemical, Units, n, max, min, median, mean, `standard deviation`, 
         `Overall Trend`, `recent (8) Trend`, `Data handling consideration`,
         `Tested Data Distribution`,`CI Calculation Method`, DF, UCL, LCL,
         GWPS,`95% LCL > GWPS`, `bootstrap iterations`, `bootstrap median`)

colnames(LCLtbl) <- c("Location",
                        "Constituent", "Units",
                        "n",
                        "max (Rank n)","min (Rank 1)",
                        "median",
                        "mean",
                        "standard deviation", 
                      "Overall Trend", "Recent (8) Trend",
                      "Data handling", "CI dataset distribution",
                      "CI calculation method",
                        "degrees of freedom",
                        "95% Confidence UCL",
                        "95% Confidence LCL",
                       # "99% Confidence UCL",
                       #  "99% Confidence LCL",
                      "GWPS", "LCL > GWPS?", 
                        "bootstrap iterations",
                        "bootstrap median")


a8 <-
  LCLtbl %>%
  kbl(caption = "Table A-6. Confidence Intervals & SSL Identification, Assessment Monitoring",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  add_header_above(c(" " = 3,
                    "Confidence Interval (CI) Dataset" = 10,
                    "CI Calculation [a]" =4, "SSL Confirmation" = 2,
                    # "Parametric CI Statistics" = 0,
                    "Non-Parametric CI Statistics" = 2), 
                   bold = TRUE, color = "grey30") %>% 
  footnote(
    general = c("Confidence intervals are calculated for analyte/well pairs with GWPS exceedances in the event dataset.",
                "[a] The 95% lower confience level (LCL) is compared to the Groundwater Protection Standard (GWPS) to confirm a statistically significant level (SSL). The 95% upper confidence level (UCL) is also shown for purposes of comparison.")
  ) %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
    # column_spec(c(2), width_min = "90px") %>%  # Adjust width of the first column
    column_spec(c(12,14), width_min= "250px") %>%  # Adjust width of the first column
      # column_spec(c(4,5,6,7,8,9,10,11,13,15,16,17), width = "30px") %>%  # Adjust width of the first column
    column_spec(c(3,13,17,19,21), border_right = T) %>% 
      column_spec(c(1), border_left = T) %>% 
        row_spec(c(1:nrow(LCLtbl)),extra_css = "border-bottom: 0.25px solid")

print(a8)

kableExtra::save_kable(a8, "output files/Appx/Table 6. CI Calculations.html")
# library("webshot2")
# print(a8)
```
### GWPS Summary Table
**MAY NEED TO ADJUST CODE DEPENDING ON WHICH BTVS HAVE BEEN UPDATED**
```{r}
#if upls not updated

gwpstbl <- gwps %>% 
  mutate(across(c(4,6,7), \(x) formatC(x, 3))) %>% 
  arrange(Location) %>% 
  arrange(Chemical) 
colnames(gwpstbl) <- c("Background Location", "Constituent", "Units", 
                       "Background Threshold Value (BTV)", "BTV Type",
                       "MCL/RSL", "GWPS", "GWPS Source", "BTV Calculation Method")

gwpstbl[gwpstbl == ""] <- "NA"
rownames(gwpstbl) <- NULL

 a8 <-
  gwpstbl %>%
  kbl(caption = "Table A-8. Groundwater Protection Standard (GWPS) Summary",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
       column_spec(1, border_left = TRUE, width_min = "100px")  %>% 
       column_spec(c(2), width_min = "100px") %>% 
          column_spec(c(4,5,6,7), width = "80px") %>% 
    column_spec(c(1,2,3,4,5,6,7,8,9), border_right = T) %>% 
  row_spec(c(1:nrow(gwpstbl)),extra_css = "border-bottom: 0.25px solid")

print(a8)
kableExtra::save_kable(a8, "output files/Appx/Table 8. GWPS Summary.html")
```
### GWPS Comparison Table
```{r}
downgradient
gwps.compare.tbl <- gwps_comparison %>%  
  mutate(across(c(6,8), \(x) formatC(x, 3)),
         LCL= formatC(as.numeric(LCL), digits = 3)) %>% 
  arrange(Location) %>% 
  arrange(Chemical) %>% 
  arrange(desc(GWPS.Exceedance))

colnames(gwps.compare.tbl) <- c("Location", "Constituent", "Units",
                                "Sample Date", "Sample Result", 
                                "Background Threshold Value (BTV)", "BTV Type",
                       "GWPS", "GWPS Exceedance", "LCL", "SSL Confirmed")


gwps.compare.tbl[gwps.compare.tbl == ""] <- "NA"
rownames(gwps.compare.tbl) <- NULL

 a9 <-
  gwps.compare.tbl %>%
  kbl(caption = "Table A-9. Groundwater Protection Standard (GWPS) Comparison Table",
      align = "c", bold = TRUE) %>% 
  kable_classic_2(full_width = FALSE, html_font = "Calibri", font_size = 10,
                  position = "left", "striped") %>% 
  row_spec(0, bold = TRUE, color = "black", align = "center") %>%
       column_spec(1, border_left = TRUE, width_min = "100px")  %>% 
       column_spec(c(2), width_min = "100px") %>% 
          column_spec(c(4,5,6,7), width = "80px") %>% 
    column_spec(c(3,5,7,9,10,11), border_right = T) %>% 
  row_spec(c(1:nrow(gwps.compare.tbl)),extra_css = "border-bottom: 0.25px solid") %>% 
   footnote(
    general = c("BTV = Background Threshold Value, which is either the Upper Threshold Limit (UTL) or Upper Prediction Limit (UPL). GWPS = Groundwater Protection Standard, which is the max value between the BTV and the Maximum Contaminant Level/Regional Screening Level. LCL = 95% Lower Confidence Level. SSL = Statistically significant level, which is identified when an event result exceeds the GWPS and the LCL is greater than the GWPS."
    )
  ) 

print(a9)
kableExtra::save_kable(a9, "output files/Appx/Table 9. GWPS Comparison.html")

```


## Plots
```{r}
#Assessment Monitoring
for(c in unique(data_analysis$Chemical)){
#group the dataset

mk_sub <- mk_summary_all %>%  
    filter(Chemical == c,
           Location %in% wells) %>% 
  mutate(Trend_Aziz.2003 = if_else(str_detect(Trend_Aziz.2003, "Not Evaluated"), 
                                   "Not Evaluated", Trend_Aziz.2003),
         Trend8_Aziz.2003 = if_else(str_detect(Trend8_Aziz.2003, "Not Evaluated"), 
                                   "Not Evaluated", Trend8_Aziz.2003))
  
  df_sub <- subset(data_stats, Chemical == c) %>% 
    left_join(summary_SW, by = c("Location", "Chemical")) %>% 
    filter(Location %in% wells) %>% 
    mutate(detect_flag = ifelse(detect_flag == "Yes", "Detect", "Non-Detect")) %>% 
    left_join(mk_sub) %>% 
    mutate(Location = ifelse(Location %in% background.wells, paste0(Location, " (Background Well)"), Location))

CI_sub <- summary_CI %>%  filter(Chemical == c)
SSLs <- data_SSLs %>% 
  filter(Chemical == c,
         Location %in% wells) %>% 
  left_join(df_sub %>% select(c(Location))) %>% 
    distinct()    %>% 
  mutate(Location = ifelse(Location %in% background.wells, paste0(Location, " (Background Well)"), Location))

if(c %in% upls){
GWPS <- gwps_comparison %>% 
  select(Location, Chemical, GWPS) %>% 
  filter(Chemical == c) %>%  
  mutate(GWPS = as.numeric(GWPS)) %>% 
  distinct() 
}else{
  GWPS <- gwps_comparison %>% 
  select(Chemical, GWPS) %>% 
  filter(Chemical == c) %>%  
  mutate(GWPS = as.numeric(GWPS)) %>% 
  distinct() %>% 
    left_join(df_sub %>%  select(Location, Chemical) %>%  distinct())
}
  
  #Get labels for graph
  a <- df_sub$Chemical[1]
  u <- df_sub$report_result_unit[1]

  ###TIME SERIES PLOT####
  if(!c %in% unique(summary_CI$Chemical)){ 
    time_series_caption <- "Notes: GWPS = Groundwater Protection Standard (max level between the MCL/RSL and Background Threshold Value). *Recent data are considered the 8 most recent data points collected for each well/analyte.\nTrend classifications are based on Aziz (2003) guidance for Mann Kendall trend test results.\n Datasets with less than 50% non-detect results could not be evaluated for trends." 
  ggplot() +
        #DATA
        geom_line(data = df_sub, 
                  aes(x = sample_date, y = StatResult_RL), 
                  color = "black") +  # Line
        geom_point(data = df_sub, 
                   aes(x = sample_date, y = StatResult_RL, 
                       shape = detect_flag)) +  # Points
          
        #SCREENING LEVELS
        geom_hline(data = GWPS, aes(yintercept = GWPS),
                   linetype = "dashed", color = "#E69F00")+
        geom_text(data = GWPS, aes(y = GWPS, x = max(df_sub$sample_date),
                                       label = sprintf("GWPS = %s %s", format(GWPS, digits = 3), u)),
                  vjust = 1.5, hjust = 0.9, size = 3, color = "#E69F00") +
    
        # geom_hline(data = data_SSLs_sub, aes(yintercept = LCL),
        #            linetype = "dashed", color = "blue")+
        # geom_text(data = data_SSLs_sub, aes(y = LCL, x = max(sample_date),
        #                                label = sprintf("LCL = %s %s", format(LCL, digits = 3), u)),
        #           vjust = 1.5, hjust = 0.9, size = 3, color = "blue")+


        #ID Secular Trends
        geom_label(data = df_sub,
                   aes(x = min(sample_date), y = Inf),
                   label = sprintf("Trend: %s\nRecent Trend: %s",
                                   df_sub$`Trend_Aziz.2003`,
                                   df_sub$`Trend8_Aziz.2003`),
                   hjust = 0.05, vjust = 1, size = 2.5, alpha = 0.05)+

        # #ID SSIs and SSLs
        # geom_point(data = SSLs %>%  filter(!is.na(Location)),
        #            aes(x = `sample_date`, y = as.numeric(`StatResult_RL`), color = "SSL"),
        #            shape = 16, size = 3)+

        #SCALES & THEME#
        scale_shape_manual(values = c("Detect" = 16, "Non-Detect" = 1))+
        scale_color_manual(values = c("skyblue", "#D55E00"))+
        scale_x_date(breaks = date_breaks("1 year"), labels = date_format("%b-%Y")) +
        scale_y_continuous(limits = c(0,NA))+
        labs(
          title = sprintf("Assessment Monitoring Trend Analysis for %s", c),  # Main title
          x = "",  # X-axis label
          size = "",
           color = "", 
          shape = "Detection Status:",
          caption = time_series_caption,
          y = sprintf("%s (%s)", a, u)  # Y-axis label
        ) +
        theme_bw() + # Minimal theme for a cleaner look
        theme(legend.position = "bottom",
              legend.justification = c(0, 1), # Legend position in the upper left corner
              legend.box.margin = margin(-10,-10,-10,-10),
              legend.text = element_text(size = 8),
              legend.title = element_text(size = 8),
              plot.title = element_text(face = "bold", hjust = 0.5),
              plot.caption = element_text(color = "darkgrey", hjust = 0),
              strip.text = element_text(size = 9, color = "grey20", face = "bold", hjust= 0),
              strip.background = element_blank(),
              axis.text.x = element_text(angle = -90, size = 9, vjust = 0.5, hjust = 0),
              axis.text.y = element_text(size = 9),
              axis.title.y = element_text(face = "bold")
        )+
          facet_wrap(~Location, scales = "free_y")
        
    ggsave(sprintf("output files/Appx/Attachment A. Time Series for %s.pdf", c), width = 17, height = 11)
  } else {
    time_series_caption <- "Notes: GWPS = Groundwater Protection Standard (max level between the MCL/RSL and Background Threshold Value). LCL = lower confidence limits. If the LCL > GWPS, a statistically significant exceeedance is concluded.\n*Recent data are considered the 8 most recent data points collected for each well/analyte.\nTrend classifications are based on Aziz (2003) guidance for Mann Kendall trend test results.  Datasets with less than 50% non-detect results could not be evaluated for trends." 
     ggplot() +
   
        #DATA
        geom_line(data = df_sub, 
                  aes(x = sample_date, y = StatResult_RL), 
                  color = "black") +  # Line
        geom_point(data = df_sub, 
                   aes(x = sample_date, y = StatResult_RL, 
                       shape = detect_flag)) +  # Points
          
        #SCREENING LEVELS
        geom_hline(data = GWPS, aes(yintercept = GWPS, color = "GWPS"),
                   linetype = "dashed")+

        geom_hline(data = CI_sub, aes(yintercept = as.numeric(LCL), color = "LCL"),
                   linetype = "dotted")+
       
        geom_text(data = GWPS, aes(y = GWPS, x = max(df_sub$sample_date),
                                       label = sprintf("GWPS = %s %s", format(GWPS, digits = 3), u)),
                  vjust = 1.5, hjust = 0.9, size = 3, color = "#E69F00") +

        #ID Secular Trends
        geom_label(data = df_sub,
                   aes(x = min(sample_date), y = Inf),
                   label = sprintf("Trend: %s\nRecent Trend: %s",
                                   df_sub$`Trend_Aziz.2003`,
                                   df_sub$`Trend8_Aziz.2003`),
                   hjust = 0.05, vjust = 1, size = 2.5, alpha = 0.05)+

        # #ID SSIs and SSLs
        # geom_point(data = SSLs %>%  filter(!is.na(Location)),
        #            aes(x = `Sample Date`, y = as.numeric(`Sample Result (mg/L)`), color = "SSL"),
        #            shape = 16, size = 3)+

        #SCALES & THEME#
        scale_shape_manual(values = c("Detect" = 16, "Non-Detect" = 1))+
        scale_color_manual(values = c("LCL"="blue","GWPS" = "#E69F00"))+
        scale_x_date(breaks = date_breaks("1 year"), labels = date_format("%b-%Y")) +
        scale_y_continuous(limits = c(0,NA))+
        labs(
          title = sprintf("Assessment Monitoring Trend Analysis for %s", c),  # Main title
          x = "",  # X-axis label
          size = "",
           color = "", 
          shape = "Detection Status:",
          caption = time_series_caption,
          y = sprintf("%s (%s)", a, u)  # Y-axis label
        ) +
        theme_bw() + # Minimal theme for a cleaner look
        theme(legend.position = "bottom",
              legend.justification = c(0, 1), # Legend position in the upper left corner
              legend.box.margin = margin(-10,-10,-10,-10),
              legend.text = element_text(size = 8),
              legend.title = element_text(size = 8),
              plot.title = element_text(face = "bold", hjust = 0.5),
              plot.caption = element_text(color = "darkgrey", hjust = 0),
              strip.text = element_text(size = 9, color = "grey20", face = "bold", hjust= 0),
              strip.background = element_blank(),
              axis.text.x = element_text(angle = -90, size = 9, vjust = 0.5, hjust = 0),
              axis.text.y = element_text(size = 9),
              axis.title.y = element_text(face = "bold")
        )+
          facet_wrap(~Location, scales = "free_y")
        
    ggsave(sprintf("output files/Appx/Attachment A. Time Series for %s.pdf", c), width = 17, height = 11)
  }
     
     
}
  
```


#GGplotly for all data review
```{r}
data_plot <- read.csv(input.filename) %>% 
  mutate(detect_flag = ifelse(detect_flag == "Y", "Yes", "No"),
         detect_flag = ifelse(final_qualifiers == "U", "No", 
                              ifelse(final_qualifiers == "UJ", "No",
                                     detect_flag)),
         StatResult_RL = as.numeric(report_result_value),
         StatResult_RL = ifelse(report_result_unit == "ug/L", StatResult_RL/1000, StatResult_RL),
         StatResult_0.5RL = ifelse(detect_flag == "No", 0.5*StatResult_RL, StatResult_RL),
         StatResult_ND0 = ifelse(detect_flag == "No", 0, StatResult_RL),
         report_result_unit = ifelse(report_result_unit == "ug/L", "mg/L", 
                                     ifelse(report_result_unit == "pH units", "SU", 
                                            report_result_unit)),
         sample_date = as.Date(sample_date, format ="%m/%d/%Y"),
         Location = sys_loc_code,
         Location = gsub("CCR-BK-1R", "CCR-BK-1", Location),
         Location = gsub("CCR-SP-1R", "CCR-SP-1", Location),
         Chemical = chemical_name,
         Stats.Chem = ifelse(Chemical %in% c("Radium-226 & 228","Radium-226 & 228, Total"), "Yes",
                             ifelse(Chemical == "Fluoride", "Yes",
                             ifelse(fraction == "T", "Yes", "No"))),
         Chemical = ifelse(Chemical %in% c("Radium-226 & 228","Radium-226 & 228, Total"), "Radium-226 & 228", Chemical),
         key = paste(Location, Chemical, sep = "_"),
         task_code = ifelse(sample_date > "2024-05-30", "Round X", task_code)) %>% 
  filter(task_code != "",
         task_code != "129420-015",
         task_code != "CMA",
         !is.na(task_code),
         final_qualifiers != "R", #Remove rejected/unuseable results
         reportable_result == "Yes",
         report_result_unit != "mg/kg", #Remove solids data
         matrix_code == "WG", #Remove any WQ or solids data, alt approach
         sample_type_code != "FD"
         ) %>%
  distinct() %>% 
  select(c(key, Chemical, Location, sample_date, matrix_code, sample_type_code, final_qualifiers, 
           StatResult_RL, StatResult_0.5RL, StatResult_ND0, report_result_unit, detect_flag, longitude, latitude, task_code)) %>% 
  filter(Location %in% c(background.wells, wells)) %>% 
  distinct() %>% 
  filter(!grepl(", Dissolved", Chemical, ignore.case = TRUE)) %>% 
  mutate(key = paste0(Chemical, " (", report_result_unit, ")"))

shapes <- c(
   0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 
  15, 16, 17, 18, 19, 20, 21, 22, 23, 24
)
colors <- c(
  "#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", 
  "#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf",
  "#393b79", "#637939", "#8c6d31", "#843c39", "#7b4173",
  "#3182bd", "#e6550d", "#31a354", "#756bb1", "#636363",
  "#9c9ede", "#ff9896", "#98df8a", "#c5b0d5", "#c49c94"
)
library(plotly)  
ggplotly(
ggplot(data = data_plot,
       aes(x = sample_date, y = StatResult_RL, color = Location, shape = Location))+
  scale_color_manual(values = colors)+
  scale_shape_manual(values = shapes)+
  geom_point()+
  geom_line()+
  facet_wrap(~key, scales = "free")+
  theme_bw()
)
```

